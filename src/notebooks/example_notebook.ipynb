{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "standing-waste",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worth-publication",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def data_tranpose(df):\n",
    "    \"\"\"\n",
    "    Transposing and resetting the index to train.\n",
    "    :param df:\n",
    "    :type df:\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "    df.columns.values[0] = \"\"\n",
    "    df.set_index(df.columns[0], inplace=True)\n",
    "\n",
    "    df_output = df.transpose()\n",
    "    df_output.reset_index(drop=True, inplace=True)\n",
    "    df_output = df_output.astype(\"float32\")\n",
    "\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "saved-release",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_fitted = pd.read_csv(\"../forecasts/prison_arima_fitted.csv\")\n",
    "df_actual = pd.read_csv(\"../input_data/prison_actual.csv\")\n",
    "df_forecasts = pd.read_csv(\"../forecasts/prison_arima_forecasts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "00d33aaf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df_actual_transpose['Aggregated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "irish-disclaimer",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#df_ets_forecasts = pd.read_csv(\"prison/prison_ets_forecasts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "civic-firewall",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#df_forecasts.iloc[0,2:] = df_ets_forecasts.iloc[0,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "interpreted-oriental",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_feature_tranpose = data_tranpose(df_fitted)\n",
    "df_actual_transpose = data_tranpose(df_actual)\n",
    "df_forecasts_transpose = data_tranpose(df_forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8d0a2bb9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "64678e0f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature_tranpose.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "opened-gibson",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 121)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature_tranpose.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "caroline-combining",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 121)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actual_transpose.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "charitable-winning",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aggregated</th>\n",
       "      <th>ACT</th>\n",
       "      <th>NSW</th>\n",
       "      <th>NT</th>\n",
       "      <th>QLD</th>\n",
       "      <th>SA</th>\n",
       "      <th>TAS</th>\n",
       "      <th>VIC</th>\n",
       "      <th>WA</th>\n",
       "      <th>ACT-Female</th>\n",
       "      <th>...</th>\n",
       "      <th>VIC-Male-Sentenced-ATSI</th>\n",
       "      <th>VIC-Male-Sentenced-Non-ATSI</th>\n",
       "      <th>WA-Female-Remanded-ATSI</th>\n",
       "      <th>WA-Female-Remanded-Non-ATSI</th>\n",
       "      <th>WA-Female-Sentenced-ATSI</th>\n",
       "      <th>WA-Female-Sentenced-Non-ATSI</th>\n",
       "      <th>WA-Male-Remanded-ATSI</th>\n",
       "      <th>WA-Male-Remanded-Non-ATSI</th>\n",
       "      <th>WA-Male-Sentenced-ATSI</th>\n",
       "      <th>WA-Male-Sentenced-Non-ATSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24296.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>9018.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>5294.0</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>3534.0</td>\n",
       "      <td>3410.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2563.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>1587.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24643.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>9099.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>5345.0</td>\n",
       "      <td>1511.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3592.0</td>\n",
       "      <td>3551.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2623.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24511.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>9007.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>5368.0</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>3678.0</td>\n",
       "      <td>3416.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>146.0</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24393.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>8991.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>5321.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>3649.0</td>\n",
       "      <td>3393.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2658.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>1620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24524.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>9103.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>5423.0</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>3556.0</td>\n",
       "      <td>3434.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>151.0</td>\n",
       "      <td>2582.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>1644.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Aggregated    ACT     NSW     NT     QLD      SA    TAS     VIC      WA  \\\n",
       "0     24296.0  178.0  9018.0  785.0  5294.0  1552.0  525.0  3534.0  3410.0   \n",
       "1     24643.0  183.0  9099.0  822.0  5345.0  1511.0  540.0  3592.0  3551.0   \n",
       "2     24511.0  187.0  9007.0  796.0  5368.0  1530.0  529.0  3678.0  3416.0   \n",
       "3     24393.0  204.0  8991.0  760.0  5321.0  1556.0  519.0  3649.0  3393.0   \n",
       "4     24524.0  190.0  9103.0  806.0  5423.0  1536.0  476.0  3556.0  3434.0   \n",
       "\n",
       "   ACT-Female  ...  VIC-Male-Sentenced-ATSI  VIC-Male-Sentenced-Non-ATSI  \\\n",
       "0         7.0  ...                    126.0                       2563.0   \n",
       "1        10.0  ...                    127.0                       2623.0   \n",
       "2         6.0  ...                    146.0                       2682.0   \n",
       "3        12.0  ...                    147.0                       2658.0   \n",
       "4        13.0  ...                    151.0                       2582.0   \n",
       "\n",
       "   WA-Female-Remanded-ATSI  WA-Female-Remanded-Non-ATSI  \\\n",
       "0                     34.0                         27.0   \n",
       "1                     24.0                         28.0   \n",
       "2                     28.0                         21.0   \n",
       "3                     19.0                         24.0   \n",
       "4                     29.0                         24.0   \n",
       "\n",
       "   WA-Female-Sentenced-ATSI  WA-Female-Sentenced-Non-ATSI  \\\n",
       "0                     115.0                          95.0   \n",
       "1                     114.0                         102.0   \n",
       "2                      99.0                         102.0   \n",
       "3                      97.0                          96.0   \n",
       "4                      96.0                          98.0   \n",
       "\n",
       "   WA-Male-Remanded-ATSI  WA-Male-Remanded-Non-ATSI  WA-Male-Sentenced-ATSI  \\\n",
       "0                  189.0                      306.0                  1057.0   \n",
       "1                  186.0                      332.0                  1125.0   \n",
       "2                  178.0                      326.0                  1070.0   \n",
       "3                  181.0                      307.0                  1049.0   \n",
       "4                  214.0                      316.0                  1013.0   \n",
       "\n",
       "   WA-Male-Sentenced-Non-ATSI  \n",
       "0                      1587.0  \n",
       "1                      1640.0  \n",
       "2                      1592.0  \n",
       "3                      1620.0  \n",
       "4                      1644.0  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actual_transpose.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "global-prevention",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 121)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_forecasts_transpose.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "distant-range",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aggregated</th>\n",
       "      <th>ACT</th>\n",
       "      <th>NSW</th>\n",
       "      <th>NT</th>\n",
       "      <th>QLD</th>\n",
       "      <th>SA</th>\n",
       "      <th>TAS</th>\n",
       "      <th>VIC</th>\n",
       "      <th>WA</th>\n",
       "      <th>ACT-Female</th>\n",
       "      <th>...</th>\n",
       "      <th>VIC-Male-Sentenced-ATSI</th>\n",
       "      <th>VIC-Male-Sentenced-Non-ATSI</th>\n",
       "      <th>WA-Female-Remanded-ATSI</th>\n",
       "      <th>WA-Female-Remanded-Non-ATSI</th>\n",
       "      <th>WA-Female-Sentenced-ATSI</th>\n",
       "      <th>WA-Female-Sentenced-Non-ATSI</th>\n",
       "      <th>WA-Male-Remanded-ATSI</th>\n",
       "      <th>WA-Male-Remanded-Non-ATSI</th>\n",
       "      <th>WA-Male-Sentenced-ATSI</th>\n",
       "      <th>WA-Male-Sentenced-Non-ATSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35238.511719</td>\n",
       "      <td>347.230774</td>\n",
       "      <td>10734.232422</td>\n",
       "      <td>1587.358887</td>\n",
       "      <td>7382.901855</td>\n",
       "      <td>2737.328125</td>\n",
       "      <td>437.392548</td>\n",
       "      <td>6568.919434</td>\n",
       "      <td>5444.671387</td>\n",
       "      <td>16.769266</td>\n",
       "      <td>...</td>\n",
       "      <td>364.974365</td>\n",
       "      <td>4327.782715</td>\n",
       "      <td>86.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>188.937164</td>\n",
       "      <td>189.418045</td>\n",
       "      <td>446.092316</td>\n",
       "      <td>648.564087</td>\n",
       "      <td>1432.727295</td>\n",
       "      <td>2375.884521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35845.503906</td>\n",
       "      <td>351.461548</td>\n",
       "      <td>10921.754883</td>\n",
       "      <td>1597.791138</td>\n",
       "      <td>7543.861328</td>\n",
       "      <td>2811.419678</td>\n",
       "      <td>457.783661</td>\n",
       "      <td>6708.636230</td>\n",
       "      <td>5514.964844</td>\n",
       "      <td>16.769266</td>\n",
       "      <td>...</td>\n",
       "      <td>370.948730</td>\n",
       "      <td>4373.406738</td>\n",
       "      <td>86.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>188.937164</td>\n",
       "      <td>191.809113</td>\n",
       "      <td>462.648041</td>\n",
       "      <td>657.128235</td>\n",
       "      <td>1432.727295</td>\n",
       "      <td>2384.769287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35965.027344</td>\n",
       "      <td>355.692322</td>\n",
       "      <td>10704.757812</td>\n",
       "      <td>1603.221069</td>\n",
       "      <td>7616.755371</td>\n",
       "      <td>2878.766113</td>\n",
       "      <td>463.600006</td>\n",
       "      <td>6884.341309</td>\n",
       "      <td>5552.009766</td>\n",
       "      <td>16.769266</td>\n",
       "      <td>...</td>\n",
       "      <td>376.923065</td>\n",
       "      <td>4434.993652</td>\n",
       "      <td>86.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>188.937164</td>\n",
       "      <td>194.200195</td>\n",
       "      <td>448.909576</td>\n",
       "      <td>665.692322</td>\n",
       "      <td>1432.727295</td>\n",
       "      <td>2389.183350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36649.531250</td>\n",
       "      <td>359.923065</td>\n",
       "      <td>10714.093750</td>\n",
       "      <td>1635.202515</td>\n",
       "      <td>7736.522949</td>\n",
       "      <td>2968.016846</td>\n",
       "      <td>470.778931</td>\n",
       "      <td>7139.030762</td>\n",
       "      <td>5620.917969</td>\n",
       "      <td>16.769266</td>\n",
       "      <td>...</td>\n",
       "      <td>382.897430</td>\n",
       "      <td>4518.208496</td>\n",
       "      <td>86.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>188.937164</td>\n",
       "      <td>196.591278</td>\n",
       "      <td>453.771149</td>\n",
       "      <td>674.256409</td>\n",
       "      <td>1432.727295</td>\n",
       "      <td>2391.375977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37260.101562</td>\n",
       "      <td>364.153839</td>\n",
       "      <td>10803.640625</td>\n",
       "      <td>1653.468994</td>\n",
       "      <td>7893.648438</td>\n",
       "      <td>3038.884766</td>\n",
       "      <td>438.178345</td>\n",
       "      <td>7274.526855</td>\n",
       "      <td>5659.290039</td>\n",
       "      <td>16.769266</td>\n",
       "      <td>...</td>\n",
       "      <td>388.871796</td>\n",
       "      <td>4521.605957</td>\n",
       "      <td>86.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>188.937164</td>\n",
       "      <td>198.982346</td>\n",
       "      <td>474.194580</td>\n",
       "      <td>682.820496</td>\n",
       "      <td>1432.727295</td>\n",
       "      <td>2392.465332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Aggregated         ACT           NSW           NT          QLD  \\\n",
       "0  35238.511719  347.230774  10734.232422  1587.358887  7382.901855   \n",
       "1  35845.503906  351.461548  10921.754883  1597.791138  7543.861328   \n",
       "2  35965.027344  355.692322  10704.757812  1603.221069  7616.755371   \n",
       "3  36649.531250  359.923065  10714.093750  1635.202515  7736.522949   \n",
       "4  37260.101562  364.153839  10803.640625  1653.468994  7893.648438   \n",
       "\n",
       "            SA         TAS          VIC           WA  ACT-Female  ...  \\\n",
       "0  2737.328125  437.392548  6568.919434  5444.671387   16.769266  ...   \n",
       "1  2811.419678  457.783661  6708.636230  5514.964844   16.769266  ...   \n",
       "2  2878.766113  463.600006  6884.341309  5552.009766   16.769266  ...   \n",
       "3  2968.016846  470.778931  7139.030762  5620.917969   16.769266  ...   \n",
       "4  3038.884766  438.178345  7274.526855  5659.290039   16.769266  ...   \n",
       "\n",
       "   VIC-Male-Sentenced-ATSI  VIC-Male-Sentenced-Non-ATSI  \\\n",
       "0               364.974365                  4327.782715   \n",
       "1               370.948730                  4373.406738   \n",
       "2               376.923065                  4434.993652   \n",
       "3               382.897430                  4518.208496   \n",
       "4               388.871796                  4521.605957   \n",
       "\n",
       "   WA-Female-Remanded-ATSI  WA-Female-Remanded-Non-ATSI  \\\n",
       "0                     86.0                         61.0   \n",
       "1                     86.0                         61.0   \n",
       "2                     86.0                         61.0   \n",
       "3                     86.0                         61.0   \n",
       "4                     86.0                         61.0   \n",
       "\n",
       "   WA-Female-Sentenced-ATSI  WA-Female-Sentenced-Non-ATSI  \\\n",
       "0                188.937164                    189.418045   \n",
       "1                188.937164                    191.809113   \n",
       "2                188.937164                    194.200195   \n",
       "3                188.937164                    196.591278   \n",
       "4                188.937164                    198.982346   \n",
       "\n",
       "   WA-Male-Remanded-ATSI  WA-Male-Remanded-Non-ATSI  WA-Male-Sentenced-ATSI  \\\n",
       "0             446.092316                 648.564087             1432.727295   \n",
       "1             462.648041                 657.128235             1432.727295   \n",
       "2             448.909576                 665.692322             1432.727295   \n",
       "3             453.771149                 674.256409             1432.727295   \n",
       "4             474.194580                 682.820496             1432.727295   \n",
       "\n",
       "   WA-Male-Sentenced-Non-ATSI  \n",
       "0                 2375.884521  \n",
       "1                 2384.769287  \n",
       "2                 2389.183350  \n",
       "3                 2391.375977  \n",
       "4                 2392.465332  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_forecasts_transpose.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "conservative-sitting",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# upper level fitted time series\n",
    "df_level1_ts = df_feature_tranpose.columns[0]\n",
    "df_level2_ts = df_feature_tranpose.columns[1:9]\n",
    "df_level3_ts = df_feature_tranpose.columns[9:(10+16-1)]\n",
    "df_level4_ts = df_feature_tranpose.columns[25:(26+32-1)]\n",
    "df_level5_ts = df_feature_tranpose.columns[57:(58+64-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b6689018",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ACT-Female', 'ACT-Male', 'NSW-Female', 'NSW-Male', 'NT-Female',\n",
       "       'NT-Male', 'QLD-Female', 'QLD-Male', 'SA-Female', 'SA-Male',\n",
       "       'TAS-Female', 'TAS-Male', 'VIC-Female', 'VIC-Male', 'WA-Female',\n",
       "       'WA-Male'],\n",
       "      dtype='object', name='')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_level3_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "respiratory-positive",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_level5_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "spread-alarm",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "matching_level1_indexes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "intense-personal",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "matching_level1_indexes[0] = np.arange(57,121).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "incomplete-mississippi",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [57,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  96,\n",
       "  97,\n",
       "  98,\n",
       "  99,\n",
       "  100,\n",
       "  101,\n",
       "  102,\n",
       "  103,\n",
       "  104,\n",
       "  105,\n",
       "  106,\n",
       "  107,\n",
       "  108,\n",
       "  109,\n",
       "  110,\n",
       "  111,\n",
       "  112,\n",
       "  113,\n",
       "  114,\n",
       "  115,\n",
       "  116,\n",
       "  117,\n",
       "  118,\n",
       "  119,\n",
       "  120]}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_level1_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fatty-morrison",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "matching_level2_indexes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "sudden-conservative",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "matching_level2_bottom_split = [i.split('-', 1)[0] for i in df_level5_ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9afcf891",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# matching_level2_bottom_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "victorian-diploma",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for var in range(1,9):\n",
    "    match_name = df_feature_tranpose.columns[var]\n",
    "    indices = [i for i, s in enumerate(matching_level2_bottom_split) if match_name in s]\n",
    "    matching_level2_indexes[var] = [x+57 for x in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "twenty-portable",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [57, 58, 59, 60, 61, 62, 63, 64],\n",
       " 2: [65, 66, 67, 68, 69, 70, 71, 72],\n",
       " 3: [73, 74, 75, 76, 77, 78, 79, 80],\n",
       " 4: [81, 82, 83, 84, 85, 86, 87, 88],\n",
       " 5: [89, 90, 91, 92, 93, 94, 95, 96],\n",
       " 6: [97, 98, 99, 100, 101, 102, 103, 104],\n",
       " 7: [105, 106, 107, 108, 109, 110, 111, 112],\n",
       " 8: [113, 114, 115, 116, 117, 118, 119, 120]}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_level2_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "defbc27d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# find_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "alleged-deficit",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "matching_level3_indexes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "handmade-relief",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "matching_level3_bottom_split = [\"-\".join(i.split(\"-\", 2)[:2]) for i in df_level5_ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "balanced-bulgarian",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for var in range(9,25):\n",
    "    match_name = df_feature_tranpose.columns[var]\n",
    "    indices = [i for i, s in enumerate(matching_level3_bottom_split) if match_name in s]\n",
    "    matching_level3_indexes[var] = [x+57 for x in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "selective-lincoln",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{9: [57, 58, 59, 60],\n",
       " 10: [61, 62, 63, 64],\n",
       " 11: [65, 66, 67, 68],\n",
       " 12: [69, 70, 71, 72],\n",
       " 13: [73, 74, 75, 76],\n",
       " 14: [77, 78, 79, 80],\n",
       " 15: [81, 82, 83, 84],\n",
       " 16: [85, 86, 87, 88],\n",
       " 17: [89, 90, 91, 92],\n",
       " 18: [93, 94, 95, 96],\n",
       " 19: [97, 98, 99, 100],\n",
       " 20: [101, 102, 103, 104],\n",
       " 21: [105, 106, 107, 108],\n",
       " 22: [109, 110, 111, 112],\n",
       " 23: [113, 114, 115, 116],\n",
       " 24: [117, 118, 119, 120]}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_level3_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "independent-fleece",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "matching_level4_indexes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "classified-salvation",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "matching_level4_bottom_split = [\"-\".join(i.split(\"-\", 3)[:3]) for i in df_level5_ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "sporting-arcade",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for var in range(25,57):\n",
    "    match_name = df_feature_tranpose.columns[var]\n",
    "    indices = [i for i, s in enumerate(matching_level4_bottom_split) if match_name in s]\n",
    "    matching_level4_indexes[var] = [x+57 for x in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "oriented-garden",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{25: [57, 58],\n",
       " 26: [59, 60],\n",
       " 27: [61, 62],\n",
       " 28: [63, 64],\n",
       " 29: [65, 66],\n",
       " 30: [67, 68],\n",
       " 31: [69, 70],\n",
       " 32: [71, 72],\n",
       " 33: [73, 74],\n",
       " 34: [75, 76],\n",
       " 35: [77, 78],\n",
       " 36: [79, 80],\n",
       " 37: [81, 82],\n",
       " 38: [83, 84],\n",
       " 39: [85, 86],\n",
       " 40: [87, 88],\n",
       " 41: [89, 90],\n",
       " 42: [91, 92],\n",
       " 43: [93, 94],\n",
       " 44: [95, 96],\n",
       " 45: [97, 98],\n",
       " 46: [99, 100],\n",
       " 47: [101, 102],\n",
       " 48: [103, 104],\n",
       " 49: [105, 106],\n",
       " 50: [107, 108],\n",
       " 51: [109, 110],\n",
       " 52: [111, 112],\n",
       " 53: [113, 114],\n",
       " 54: [115, 116],\n",
       " 55: [117, 118],\n",
       " 56: [119, 120]}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_level4_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "satellite-model",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aggregated</th>\n",
       "      <th>ACT</th>\n",
       "      <th>NSW</th>\n",
       "      <th>NT</th>\n",
       "      <th>QLD</th>\n",
       "      <th>SA</th>\n",
       "      <th>TAS</th>\n",
       "      <th>VIC</th>\n",
       "      <th>WA</th>\n",
       "      <th>ACT-Female</th>\n",
       "      <th>...</th>\n",
       "      <th>VIC-Male-Sentenced-ATSI</th>\n",
       "      <th>VIC-Male-Sentenced-Non-ATSI</th>\n",
       "      <th>WA-Female-Remanded-ATSI</th>\n",
       "      <th>WA-Female-Remanded-Non-ATSI</th>\n",
       "      <th>WA-Female-Sentenced-ATSI</th>\n",
       "      <th>WA-Female-Sentenced-Non-ATSI</th>\n",
       "      <th>WA-Male-Remanded-ATSI</th>\n",
       "      <th>WA-Male-Remanded-Non-ATSI</th>\n",
       "      <th>WA-Male-Sentenced-ATSI</th>\n",
       "      <th>WA-Male-Sentenced-Non-ATSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24271.703125</td>\n",
       "      <td>177.826233</td>\n",
       "      <td>9008.982422</td>\n",
       "      <td>784.233826</td>\n",
       "      <td>5291.632324</td>\n",
       "      <td>1551.305908</td>\n",
       "      <td>524.473083</td>\n",
       "      <td>3531.959717</td>\n",
       "      <td>3406.643311</td>\n",
       "      <td>6.993000</td>\n",
       "      <td>...</td>\n",
       "      <td>125.879974</td>\n",
       "      <td>2560.481445</td>\n",
       "      <td>33.966</td>\n",
       "      <td>26.973</td>\n",
       "      <td>114.885002</td>\n",
       "      <td>94.907394</td>\n",
       "      <td>188.817474</td>\n",
       "      <td>305.702576</td>\n",
       "      <td>1055.942993</td>\n",
       "      <td>1585.412964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24456.992188</td>\n",
       "      <td>182.230774</td>\n",
       "      <td>9041.748047</td>\n",
       "      <td>805.233093</td>\n",
       "      <td>5351.988770</td>\n",
       "      <td>1513.173950</td>\n",
       "      <td>539.456116</td>\n",
       "      <td>3591.042480</td>\n",
       "      <td>3482.317383</td>\n",
       "      <td>7.387423</td>\n",
       "      <td>...</td>\n",
       "      <td>131.974365</td>\n",
       "      <td>2611.741699</td>\n",
       "      <td>34.000</td>\n",
       "      <td>27.000</td>\n",
       "      <td>114.901596</td>\n",
       "      <td>97.544830</td>\n",
       "      <td>194.014450</td>\n",
       "      <td>314.564117</td>\n",
       "      <td>1062.202515</td>\n",
       "      <td>1594.003784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24753.003906</td>\n",
       "      <td>187.230774</td>\n",
       "      <td>9105.125000</td>\n",
       "      <td>837.381958</td>\n",
       "      <td>5388.567383</td>\n",
       "      <td>1491.045410</td>\n",
       "      <td>528.465210</td>\n",
       "      <td>3677.300537</td>\n",
       "      <td>3618.820068</td>\n",
       "      <td>8.616979</td>\n",
       "      <td>...</td>\n",
       "      <td>132.974365</td>\n",
       "      <td>2675.820801</td>\n",
       "      <td>24.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>113.304741</td>\n",
       "      <td>105.524025</td>\n",
       "      <td>190.246231</td>\n",
       "      <td>340.564117</td>\n",
       "      <td>1148.104004</td>\n",
       "      <td>1666.329956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24461.708984</td>\n",
       "      <td>191.230774</td>\n",
       "      <td>8980.875000</td>\n",
       "      <td>810.611938</td>\n",
       "      <td>5380.762207</td>\n",
       "      <td>1519.998901</td>\n",
       "      <td>518.473267</td>\n",
       "      <td>3649.917969</td>\n",
       "      <td>3346.844727</td>\n",
       "      <td>7.474558</td>\n",
       "      <td>...</td>\n",
       "      <td>151.974365</td>\n",
       "      <td>2719.242920</td>\n",
       "      <td>28.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>92.300476</td>\n",
       "      <td>103.458305</td>\n",
       "      <td>183.936325</td>\n",
       "      <td>334.564117</td>\n",
       "      <td>1037.984863</td>\n",
       "      <td>1568.154053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24455.775391</td>\n",
       "      <td>208.230774</td>\n",
       "      <td>9022.333984</td>\n",
       "      <td>780.926392</td>\n",
       "      <td>5331.057129</td>\n",
       "      <td>1549.878418</td>\n",
       "      <td>498.102631</td>\n",
       "      <td>3563.627686</td>\n",
       "      <td>3453.395752</td>\n",
       "      <td>9.486750</td>\n",
       "      <td>...</td>\n",
       "      <td>152.974365</td>\n",
       "      <td>2660.540283</td>\n",
       "      <td>19.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>99.241249</td>\n",
       "      <td>96.415283</td>\n",
       "      <td>191.545792</td>\n",
       "      <td>315.564117</td>\n",
       "      <td>1053.550781</td>\n",
       "      <td>1633.910156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Aggregated         ACT          NSW          NT          QLD  \\\n",
       "0  24271.703125  177.826233  9008.982422  784.233826  5291.632324   \n",
       "1  24456.992188  182.230774  9041.748047  805.233093  5351.988770   \n",
       "2  24753.003906  187.230774  9105.125000  837.381958  5388.567383   \n",
       "3  24461.708984  191.230774  8980.875000  810.611938  5380.762207   \n",
       "4  24455.775391  208.230774  9022.333984  780.926392  5331.057129   \n",
       "\n",
       "            SA         TAS          VIC           WA  ACT-Female  ...  \\\n",
       "0  1551.305908  524.473083  3531.959717  3406.643311    6.993000  ...   \n",
       "1  1513.173950  539.456116  3591.042480  3482.317383    7.387423  ...   \n",
       "2  1491.045410  528.465210  3677.300537  3618.820068    8.616979  ...   \n",
       "3  1519.998901  518.473267  3649.917969  3346.844727    7.474558  ...   \n",
       "4  1549.878418  498.102631  3563.627686  3453.395752    9.486750  ...   \n",
       "\n",
       "   VIC-Male-Sentenced-ATSI  VIC-Male-Sentenced-Non-ATSI  \\\n",
       "0               125.879974                  2560.481445   \n",
       "1               131.974365                  2611.741699   \n",
       "2               132.974365                  2675.820801   \n",
       "3               151.974365                  2719.242920   \n",
       "4               152.974365                  2660.540283   \n",
       "\n",
       "   WA-Female-Remanded-ATSI  WA-Female-Remanded-Non-ATSI  \\\n",
       "0                   33.966                       26.973   \n",
       "1                   34.000                       27.000   \n",
       "2                   24.000                       28.000   \n",
       "3                   28.000                       21.000   \n",
       "4                   19.000                       24.000   \n",
       "\n",
       "   WA-Female-Sentenced-ATSI  WA-Female-Sentenced-Non-ATSI  \\\n",
       "0                114.885002                     94.907394   \n",
       "1                114.901596                     97.544830   \n",
       "2                113.304741                    105.524025   \n",
       "3                 92.300476                    103.458305   \n",
       "4                 99.241249                     96.415283   \n",
       "\n",
       "   WA-Male-Remanded-ATSI  WA-Male-Remanded-Non-ATSI  WA-Male-Sentenced-ATSI  \\\n",
       "0             188.817474                 305.702576             1055.942993   \n",
       "1             194.014450                 314.564117             1062.202515   \n",
       "2             190.246231                 340.564117             1148.104004   \n",
       "3             183.936325                 334.564117             1037.984863   \n",
       "4             191.545792                 315.564117             1053.550781   \n",
       "\n",
       "   WA-Male-Sentenced-Non-ATSI  \n",
       "0                 1585.412964  \n",
       "1                 1594.003784  \n",
       "2                 1666.329956  \n",
       "3                 1568.154053  \n",
       "4                 1633.910156  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature_tranpose.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "logical-software",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aggregated</th>\n",
       "      <th>ACT</th>\n",
       "      <th>NSW</th>\n",
       "      <th>NT</th>\n",
       "      <th>QLD</th>\n",
       "      <th>SA</th>\n",
       "      <th>TAS</th>\n",
       "      <th>VIC</th>\n",
       "      <th>WA</th>\n",
       "      <th>ACT-Female</th>\n",
       "      <th>...</th>\n",
       "      <th>VIC-Male-Sentenced-ATSI</th>\n",
       "      <th>VIC-Male-Sentenced-Non-ATSI</th>\n",
       "      <th>WA-Female-Remanded-ATSI</th>\n",
       "      <th>WA-Female-Remanded-Non-ATSI</th>\n",
       "      <th>WA-Female-Sentenced-ATSI</th>\n",
       "      <th>WA-Female-Sentenced-Non-ATSI</th>\n",
       "      <th>WA-Male-Remanded-ATSI</th>\n",
       "      <th>WA-Male-Remanded-Non-ATSI</th>\n",
       "      <th>WA-Male-Sentenced-ATSI</th>\n",
       "      <th>WA-Male-Sentenced-Non-ATSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24296.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>9018.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>5294.0</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>3534.0</td>\n",
       "      <td>3410.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2563.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>1587.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24643.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>9099.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>5345.0</td>\n",
       "      <td>1511.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3592.0</td>\n",
       "      <td>3551.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2623.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24511.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>9007.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>5368.0</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>3678.0</td>\n",
       "      <td>3416.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>146.0</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24393.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>8991.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>5321.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>3649.0</td>\n",
       "      <td>3393.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2658.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>1620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24524.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>9103.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>5423.0</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>3556.0</td>\n",
       "      <td>3434.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>151.0</td>\n",
       "      <td>2582.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>1644.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Aggregated    ACT     NSW     NT     QLD      SA    TAS     VIC      WA  \\\n",
       "0     24296.0  178.0  9018.0  785.0  5294.0  1552.0  525.0  3534.0  3410.0   \n",
       "1     24643.0  183.0  9099.0  822.0  5345.0  1511.0  540.0  3592.0  3551.0   \n",
       "2     24511.0  187.0  9007.0  796.0  5368.0  1530.0  529.0  3678.0  3416.0   \n",
       "3     24393.0  204.0  8991.0  760.0  5321.0  1556.0  519.0  3649.0  3393.0   \n",
       "4     24524.0  190.0  9103.0  806.0  5423.0  1536.0  476.0  3556.0  3434.0   \n",
       "\n",
       "   ACT-Female  ...  VIC-Male-Sentenced-ATSI  VIC-Male-Sentenced-Non-ATSI  \\\n",
       "0         7.0  ...                    126.0                       2563.0   \n",
       "1        10.0  ...                    127.0                       2623.0   \n",
       "2         6.0  ...                    146.0                       2682.0   \n",
       "3        12.0  ...                    147.0                       2658.0   \n",
       "4        13.0  ...                    151.0                       2582.0   \n",
       "\n",
       "   WA-Female-Remanded-ATSI  WA-Female-Remanded-Non-ATSI  \\\n",
       "0                     34.0                         27.0   \n",
       "1                     24.0                         28.0   \n",
       "2                     28.0                         21.0   \n",
       "3                     19.0                         24.0   \n",
       "4                     29.0                         24.0   \n",
       "\n",
       "   WA-Female-Sentenced-ATSI  WA-Female-Sentenced-Non-ATSI  \\\n",
       "0                     115.0                          95.0   \n",
       "1                     114.0                         102.0   \n",
       "2                      99.0                         102.0   \n",
       "3                      97.0                          96.0   \n",
       "4                      96.0                          98.0   \n",
       "\n",
       "   WA-Male-Remanded-ATSI  WA-Male-Remanded-Non-ATSI  WA-Male-Sentenced-ATSI  \\\n",
       "0                  189.0                      306.0                  1057.0   \n",
       "1                  186.0                      332.0                  1125.0   \n",
       "2                  178.0                      326.0                  1070.0   \n",
       "3                  181.0                      307.0                  1049.0   \n",
       "4                  214.0                      316.0                  1013.0   \n",
       "\n",
       "   WA-Male-Sentenced-Non-ATSI  \n",
       "0                      1587.0  \n",
       "1                      1640.0  \n",
       "2                      1592.0  \n",
       "3                      1620.0  \n",
       "4                      1644.0  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actual_transpose.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "rural-eugene",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_final_labels = df_actual_transpose.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "69ad2b39",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "57+64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f5f5fd50",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df_actual_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2ced6b56",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df_final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "acceptable-sailing",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(df_feature_tranpose, df_final_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "conditional-memorial",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train))  # training set\n",
    "X_valid = pd.DataFrame(scaler.transform(X_valid))  # validation set\n",
    "df_feature_scaled_test = pd.DataFrame(scaler.transform(df_feature_tranpose))  # training set during testing\n",
    "df_forecasts_scaled = pd.DataFrame(scaler.transform(df_forecasts_transpose))  # testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "studied-batch",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "label_size = df_final_labels.iloc[:,57:].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "wrapped-undergraduate",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "heated-community",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_indexes = {**matching_level1_indexes, **matching_level2_indexes, **matching_level3_indexes, **matching_level4_indexes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "virtual-louis",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [57,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  96,\n",
       "  97,\n",
       "  98,\n",
       "  99,\n",
       "  100,\n",
       "  101,\n",
       "  102,\n",
       "  103,\n",
       "  104,\n",
       "  105,\n",
       "  106,\n",
       "  107,\n",
       "  108,\n",
       "  109,\n",
       "  110,\n",
       "  111,\n",
       "  112,\n",
       "  113,\n",
       "  114,\n",
       "  115,\n",
       "  116,\n",
       "  117,\n",
       "  118,\n",
       "  119,\n",
       "  120],\n",
       " 1: [57, 58, 59, 60, 61, 62, 63, 64],\n",
       " 2: [65, 66, 67, 68, 69, 70, 71, 72],\n",
       " 3: [73, 74, 75, 76, 77, 78, 79, 80],\n",
       " 4: [81, 82, 83, 84, 85, 86, 87, 88],\n",
       " 5: [89, 90, 91, 92, 93, 94, 95, 96],\n",
       " 6: [97, 98, 99, 100, 101, 102, 103, 104],\n",
       " 7: [105, 106, 107, 108, 109, 110, 111, 112],\n",
       " 8: [113, 114, 115, 116, 117, 118, 119, 120],\n",
       " 9: [57, 58, 59, 60],\n",
       " 10: [61, 62, 63, 64],\n",
       " 11: [65, 66, 67, 68],\n",
       " 12: [69, 70, 71, 72],\n",
       " 13: [73, 74, 75, 76],\n",
       " 14: [77, 78, 79, 80],\n",
       " 15: [81, 82, 83, 84],\n",
       " 16: [85, 86, 87, 88],\n",
       " 17: [89, 90, 91, 92],\n",
       " 18: [93, 94, 95, 96],\n",
       " 19: [97, 98, 99, 100],\n",
       " 20: [101, 102, 103, 104],\n",
       " 21: [105, 106, 107, 108],\n",
       " 22: [109, 110, 111, 112],\n",
       " 23: [113, 114, 115, 116],\n",
       " 24: [117, 118, 119, 120],\n",
       " 25: [57, 58],\n",
       " 26: [59, 60],\n",
       " 27: [61, 62],\n",
       " 28: [63, 64],\n",
       " 29: [65, 66],\n",
       " 30: [67, 68],\n",
       " 31: [69, 70],\n",
       " 32: [71, 72],\n",
       " 33: [73, 74],\n",
       " 34: [75, 76],\n",
       " 35: [77, 78],\n",
       " 36: [79, 80],\n",
       " 37: [81, 82],\n",
       " 38: [83, 84],\n",
       " 39: [85, 86],\n",
       " 40: [87, 88],\n",
       " 41: [89, 90],\n",
       " 42: [91, 92],\n",
       " 43: [93, 94],\n",
       " 44: [95, 96],\n",
       " 45: [97, 98],\n",
       " 46: [99, 100],\n",
       " 47: [101, 102],\n",
       " 48: [103, 104],\n",
       " 49: [105, 106],\n",
       " 50: [107, 108],\n",
       " 51: [109, 110],\n",
       " 52: [111, 112],\n",
       " 53: [113, 114],\n",
       " 54: [115, 116],\n",
       " 55: [117, 118],\n",
       " 56: [119, 120]}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "dietary-isaac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###### Model building\n",
    "def custom_loss_fn(reconciliation_loss_lambda):\n",
    "    def loss(data, y_pred):\n",
    "        \"\"\"\n",
    "        Computes the custom loss for model training, given the actuals and predictions\n",
    "        :param data:\n",
    "        :type data:\n",
    "        :param y_pred:\n",
    "        :type y_pred:\n",
    "        :return:\n",
    "        :rtype:\n",
    "        \"\"\"\n",
    "        rec_loss_list = list()\n",
    "#         all_predictions = y_pred[:, :64]\n",
    "        all_predictions = y_pred\n",
    "        actual = data[:, 57:]\n",
    "        print(data)\n",
    "        # prediction error\n",
    "        loss_fn = tf.losses.MeanSquaredError()\n",
    "        prediction_error = loss_fn(actual, all_predictions)\n",
    "        \n",
    "        # Reconcilation error\n",
    "        for key in all_indexes:\n",
    "            higher_hie_index = key\n",
    "            lower_hie_index = all_indexes[higher_hie_index]\n",
    "\n",
    "            higher_hie_ts = tf.reshape(data[:, higher_hie_index], [-1, 1])\n",
    "            higher_hie_ts_actual = higher_hie_ts\n",
    "            \n",
    "            lower_index = (lower_hie_index[0] - 57)\n",
    "            high_index = (lower_hie_index[-1] - 57)\n",
    "\n",
    "            lower_hie_ts = y_pred[:, lower_index: (high_index + 1)]\n",
    "            lower_hie_ts_agg_pred = tf.reduce_sum(lower_hie_ts, axis=1, keepdims=True)\n",
    "            recon_loss = tf.math.reduce_mean(tf.square(higher_hie_ts_actual - lower_hie_ts_agg_pred))\n",
    "            rec_loss_list.append(recon_loss)\n",
    "\n",
    "        recon_loss_agg = tf.reduce_sum(rec_loss_list)\n",
    "        final_loss = prediction_error + reconciliation_loss_lambda* recon_loss_agg\n",
    "        return final_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "recorded-parliament",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def val_loss_fn(y_actual, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the error for the validation set\n",
    "    :param y_actual:\n",
    "    :type y_actual:\n",
    "    :param y_pred:\n",
    "    :type y_pred:\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    val_loss = np.mean(np.sqrt(tf.losses.MSE(y_actual.values[:, 57:], y_pred)))\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "derived-threat",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_and_compile_model(hyperparams):\n",
    "    \"\"\"\n",
    "    Specify an FFNN model given a specific hyperparameter config\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    tf.keras.backend.clear_session()  # destroy previously built models\n",
    "    tf.random.set_seed(1234)  # set seed for reproducibility\n",
    "\n",
    "    no_layers = hyperparams['no_layers']\n",
    "    no_units_layer = hyperparams['no_units_layer']\n",
    "    learning_rate = hyperparams['learning_rate']\n",
    "    dropout_rate = hyperparams['dropout_rate']\n",
    "    max_norm_value = hyperparams['max_norm_value']\n",
    "    reconciliation_loss_lambda = hyperparams['reconciliation_loss_lambda']\n",
    "\n",
    "    inputs = keras.Input(shape=df_feature_tranpose.shape[1])\n",
    "    last_output = inputs\n",
    "    for layer in range(no_layers):\n",
    "        layer_output = layers.Dense(no_units_layer[layer],\n",
    "                                   kernel_constraint=max_norm(max_norm_value))(last_output)\n",
    "        x = layers.BatchNormalization()(layer_output)\n",
    "        x = keras.activations.relu(x)\n",
    "        last_output = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    model_outputs = layers.Dense(label_size)(last_output)\n",
    "\n",
    "    bottom_level_actual = (inputs[:, 57:] - tf.constant(scaler.min_[57:])) / tf.constant(scaler.scale_[57:])\n",
    "    print(inputs[:, 57:].shape)\n",
    "\n",
    "    outputs = tf.add(model_outputs, bottom_level_actual)  # skip connection from input to bypass the model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(loss=custom_loss_fn(reconciliation_loss_lambda=reconciliation_loss_lambda),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "concrete-lincoln",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    \"\"\"\n",
    "    Plot the loss curves of the model\n",
    "    :param history:\n",
    "    :type history:\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    # plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.ylim([100, 200])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [MPG]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "british-stroke",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def validate_model(hyperparams):\n",
    "    \"\"\"\n",
    "    Build and train FFNN model and return the validation loss for hyperparameter\n",
    "    tuning\n",
    "    :param hyperparameters_config:\n",
    "    :type hyperparameters_config:\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    hyperparams['no_layers'] = hyperparams['layers']['no_layers']\n",
    "    hyperparams['no_units_layer'] = hyperparams['layers']['no_units_layer']\n",
    "\n",
    "    hierac_model = build_and_compile_model(hyperparams)\n",
    "\n",
    "\n",
    "    history = hierac_model.fit(\n",
    "        X_train, Y_train,\n",
    "        batch_size=hyperparams['batch_size'],\n",
    "        epochs=hyperparams['epochs'],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    validation_predictions = hierac_model.predict(x=X_valid)\n",
    "    val_loss = val_loss_fn(Y_valid, validation_predictions)\n",
    "\n",
    "    # hist = pd.DataFrame(history.history)\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "third-romania",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(hyperparams):\n",
    "    \"\"\"\n",
    "    Testing of the model with the best hyperparameter config found\n",
    "    :param best_hyperparams:\n",
    "    :type best_hyperparams:\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "    hyperparams['no_layers'] = int(hyperparams['layers'] + 1)\n",
    "    hyperparams['no_units_layer'] = [int(hyperparams['no_units_layer_' + str(hyperparams['layers'] + 1) + \"_\" + str(j)])\n",
    "                for j in range(1, (hyperparams['layers'] + 2))]\n",
    "    hierac_model = build_and_compile_model(hyperparams)\n",
    "\n",
    "    history = hierac_model.fit(\n",
    "        df_feature_scaled_test, df_final_labels,\n",
    "        batch_size=int(hyperparams['batch_size']),\n",
    "        epochs=int(hyperparams['epochs']),\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    plot_loss(history)\n",
    "\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    hist.head()\n",
    "\n",
    "    # forward propagate the forecasts to get the adjusted forecasts\n",
    "    adjusted_forecasts = hierac_model.predict(x=df_forecasts_scaled)\n",
    "    return adjusted_forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "demonstrated-christopher",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64)                                                                                                                                                                                                                              \n",
      "Epoch 1/55                                                                                                                                                                                                                              \n",
      "Tensor(\"IteratorGetNext:1\", shape=(None, 121), dtype=float32)                                                                                                                                                                           \n",
      "Tensor(\"IteratorGetNext:1\", shape=(None, 121), dtype=float32)                                                                                                                                                                           \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 4s - loss: 139564.9219                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - 4s 11ms/step - loss: 138335.9375                                                                                                                                                                                                     \n",
      "\n",
      "Epoch 2/55                                                                                                                                                                                                                              \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 141399.2188                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - 0s 28ms/step - loss: 139056.1094                                                                                                                                                                                                     \n",
      "\n",
      "Epoch 3/55                                                                                                                                                                                                                              \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 118305.7891                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - 0s 28ms/step - loss: 131699.5938                                                                                                                                                                                                     \n",
      "\n",
      "Epoch 4/55                                                                                                                                                                                                                              \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 126339.7031                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - 0s 15ms/step - loss: 132736.0625                                                                                                                                                                                                     \n",
      "\n",
      "Epoch 5/55                                                                                                                                                                                                                              \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 153574.8750                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - 0s 16ms/step - loss: 144492.3750                                                                                                                                                                                                     \n",
      "\n",
      "Epoch 6/55                                                                                                                                                                                                                              \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 133610.9062                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - 0s 17ms/step - loss: 143204.2031                                                                                                                                                                                                     \n",
      "\n",
      "Epoch 7/55                                                                                                                                                                                                                              \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 130106.3438                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - 0s 17ms/step - loss: 129324.8906                                                                                                                                                                                                     \n",
      "\n",
      "Epoch 8/55                                                                                                                                                                                                                              \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 125354.6172                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - 0s 16ms/step - loss: 132948.9062                                                                                                                                                                                                     \n",
      "\n",
      "Epoch 9/55                                                                                                                                                                                                                              \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 124743.9688                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - 0s 21ms/step - loss: 120814.4609                                                                                                                                                                                                     \n",
      "\n",
      "Epoch 10/55                                                                                                                                                                                                                             \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 145074.9688                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 131257.9062                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - 0s 144ms/step - loss: 131257.9062                                                                                                                                                                                                    \n",
      "\n",
      "Epoch 11/55                                                                                                                                                                                                                             \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 107629.0078                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 127942.6406                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - 0s 103ms/step - loss: 127942.6406                                                                                                                                                                                                    \n",
      "\n",
      "Epoch 12/55                                                                                                                                                                                                                             \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 129550.1953                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - 0s 22ms/step - loss: 133429.5312                                                                                                                                                                                                     \n",
      "\n",
      "Epoch 13/55                                                                                                                                                                                                                             \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 142101.6562                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - 0s 19ms/step - loss: 130581.9375                                                                                                                                                                                                     \n",
      "\n",
      "Epoch 14/55                                                                                                                                                                                                                             \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 144350.2812                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - 0s 21ms/step - loss: 140023.5781                                                                                                                                                                                                     \n",
      "\n",
      "Epoch 15/55                                                                                                                                                                                                                             \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 128354.5156                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - 0s 39ms/step - loss: 129950.8672                                                                                                                                                                                                     \n",
      "\n",
      "Epoch 16/55                                                                                                                                                                                                                             \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 168847.5156                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - 0s 20ms/step - loss: 154746.2031                                                                                                                                                                                                     \n",
      "\n",
      "Epoch 17/55                                                                                                                                                                                                                             \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 115927.0391                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - 0s 19ms/step - loss: 115580.0781                                                                                                                                                                                                     \n",
      "\n",
      "Epoch 18/55                                                                                                                                                                                                                             \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 125948.7422                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - 0s 16ms/step - loss: 112935.8125                                                                                                                                                                                                     \n",
      "\n",
      "Epoch 19/55                                                                                                                                                                                                                             \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 118835.4844                                                                                                                                                                                                          \n",
      "                                                                                                                                                                                                                                       \n",
      "2/2 [==============================]                                                                                                                                                                                                    \n",
      " - 0s 20ms/step - loss: 121945.7969                                                                                                                                                                                                     \n",
      "\n",
      "Epoch 20/55                                                                                                                                                                                                                             \n",
      "1/2 [==============>...............]                                                                                                                                                                                                    \n",
      " - ETA: 0s - loss: 113613.6328                                                                                                                                                                                                          \n",
      "  0%|                                                                                                                                                                                            | 0/50 [00:05<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/6w/fddsywgx3cs2g4z5vjzkrt2mvjsnq7/T/ipykernel_30347/532925832.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0mtrials\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTrials\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[0mmax_evals\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m50\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m best = fmin(\n\u001B[0m\u001B[1;32m     27\u001B[0m     \u001B[0mfn\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvalidate_model\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m     \u001B[0mspace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfspace\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonenv/hts-ml-env/lib/python3.8/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mfmin\u001B[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[1;32m    538\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    539\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mallow_trials_fmin\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"fmin\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 540\u001B[0;31m         return trials.fmin(\n\u001B[0m\u001B[1;32m    541\u001B[0m             \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    542\u001B[0m             \u001B[0mspace\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonenv/hts-ml-env/lib/python3.8/site-packages/hyperopt/base.py\u001B[0m in \u001B[0;36mfmin\u001B[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[1;32m    669\u001B[0m         \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mfmin\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mfmin\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    670\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 671\u001B[0;31m         return fmin(\n\u001B[0m\u001B[1;32m    672\u001B[0m             \u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    673\u001B[0m             \u001B[0mspace\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonenv/hts-ml-env/lib/python3.8/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mfmin\u001B[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001B[0m\n\u001B[1;32m    584\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    585\u001B[0m     \u001B[0;31m# next line is where the fmin is actually executed\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 586\u001B[0;31m     \u001B[0mrval\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexhaust\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    587\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    588\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mreturn_argmin\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonenv/hts-ml-env/lib/python3.8/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mexhaust\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    362\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mexhaust\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    363\u001B[0m         \u001B[0mn_done\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 364\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_evals\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mn_done\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mblock_until_done\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masynchronous\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    365\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrefresh\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    366\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonenv/hts-ml-env/lib/python3.8/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, N, block_until_done)\u001B[0m\n\u001B[1;32m    298\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    299\u001B[0m                     \u001B[0;31m# -- loop over trials and do the jobs directly\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 300\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mserial_evaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    301\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    302\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrefresh\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonenv/hts-ml-env/lib/python3.8/site-packages/hyperopt/fmin.py\u001B[0m in \u001B[0;36mserial_evaluate\u001B[0;34m(self, N)\u001B[0m\n\u001B[1;32m    176\u001B[0m                 \u001B[0mctrl\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbase\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCtrl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrials\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcurrent_trial\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    177\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 178\u001B[0;31m                     \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdomain\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspec\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctrl\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    179\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    180\u001B[0m                     \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0merror\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"job exception: %s\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonenv/hts-ml-env/lib/python3.8/site-packages/hyperopt/base.py\u001B[0m in \u001B[0;36mevaluate\u001B[0;34m(self, config, ctrl, attach_attachments)\u001B[0m\n\u001B[1;32m    890\u001B[0m                 \u001B[0mprint_node_on_error\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrec_eval_print_node_on_error\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    891\u001B[0m             )\n\u001B[0;32m--> 892\u001B[0;31m             \u001B[0mrval\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpyll_rval\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    893\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    894\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumber\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/6w/fddsywgx3cs2g4z5vjzkrt2mvjsnq7/T/ipykernel_30347/1218159141.py\u001B[0m in \u001B[0;36mvalidate_model\u001B[0;34m(hyperparams)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m     history = hierac_model.fit(\n\u001B[0m\u001B[1;32m     17\u001B[0m         \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY_train\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m         \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhyperparams\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'batch_size'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonenv/hts-ml-env/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 64\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     65\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonenv/hts-ml-env/lib/python3.8/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1214\u001B[0m                 _r=1):\n\u001B[1;32m   1215\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1216\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1217\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1218\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonenv/hts-ml-env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonenv/hts-ml-env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    908\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    909\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 910\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    911\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    912\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonenv/hts-ml-env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    940\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    941\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 942\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    943\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    944\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonenv/hts-ml-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3128\u001B[0m       (graph_function,\n\u001B[1;32m   3129\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m-> 3130\u001B[0;31m     return graph_function._call_flat(\n\u001B[0m\u001B[1;32m   3131\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[1;32m   3132\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonenv/hts-ml-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1957\u001B[0m         and executing_eagerly):\n\u001B[1;32m   1958\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1959\u001B[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[1;32m   1960\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[1;32m   1961\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[0;32m~/pythonenv/hts-ml-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    596\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    597\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 598\u001B[0;31m           outputs = execute.execute(\n\u001B[0m\u001B[1;32m    599\u001B[0m               \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    600\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/pythonenv/hts-ml-env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     56\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 58\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     59\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     60\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "######## Tune hyperparameters\n",
    "layers_upper = 5\n",
    "layers_list = []\n",
    "for i in range(1, (layers_upper + 1)):\n",
    "    layer_dict = {\n",
    "        'no_layers': i,\n",
    "        'no_units_layer': [scope.int(hp.quniform('no_units_layer_' + str(i) + \"_\" + str(j), 1, 256, 1))\n",
    "                          for j in range(1, (i+1))]\n",
    "    }\n",
    "    layers_list.append(layer_dict)\n",
    "\n",
    "fspace = {\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.0001, 0.1),\n",
    "    'layers': hp.choice('layers', layers_list),\n",
    "    'batch_size': scope.int(hp.quniform('batch_size', 1, X_train.shape[0], 1)),\n",
    "    'epochs': scope.int(hp.quniform('epochs', 10, 200, 1)),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0, 0.5),\n",
    "    'max_norm_value': hp.uniform('max_norm_value', 0, 10),\n",
    "    'reconciliation_loss_lambda': hp.uniform('reconciliation_loss_lambda', 0.1, 0.9)\n",
    "}\n",
    "\n",
    "# layers_list\n",
    "\n",
    "trials = Trials()\n",
    "max_evals = 50\n",
    "best = fmin(\n",
    "    fn=validate_model,\n",
    "    space=fspace,\n",
    "    algo=tpe.suggest,\n",
    "    trials=trials,\n",
    "    max_evals=max_evals\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "played-password",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_bottom_phie_ts = df_level5_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "subtle-concern",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/187\n",
      "2/2 [==============================] - 3s 3ms/step - loss: 183904.8490\n",
      "Epoch 2/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 178835.8646\n",
      "Epoch 3/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 183702.9948\n",
      "Epoch 4/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 155507.4635\n",
      "Epoch 5/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 164111.7865\n",
      "Epoch 6/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 160910.9010\n",
      "Epoch 7/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 153638.2448\n",
      "Epoch 8/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 140447.5156\n",
      "Epoch 9/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 140034.7969\n",
      "Epoch 10/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 133279.7344\n",
      "Epoch 11/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 130661.6927\n",
      "Epoch 12/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 116642.7083\n",
      "Epoch 13/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 117269.1641\n",
      "Epoch 14/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 124291.9479\n",
      "Epoch 15/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 119856.0833\n",
      "Epoch 16/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 101821.4948\n",
      "Epoch 17/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 114160.9062\n",
      "Epoch 18/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 112460.4427\n",
      "Epoch 19/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 92293.6693\n",
      "Epoch 20/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 103453.9766\n",
      "Epoch 21/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 97935.7214\n",
      "Epoch 22/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 91825.9505\n",
      "Epoch 23/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 89978.9948\n",
      "Epoch 24/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 86478.7917\n",
      "Epoch 25/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 90594.6354\n",
      "Epoch 26/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 97766.9115\n",
      "Epoch 27/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 96155.2500\n",
      "Epoch 28/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 88108.1510\n",
      "Epoch 29/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 92642.2943\n",
      "Epoch 30/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 80240.9974\n",
      "Epoch 31/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 74932.5299\n",
      "Epoch 32/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 81381.2370\n",
      "Epoch 33/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 77113.3672\n",
      "Epoch 34/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 81974.2552\n",
      "Epoch 35/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 79116.7917\n",
      "Epoch 36/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 89770.5078\n",
      "Epoch 37/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 73436.3255\n",
      "Epoch 38/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 82131.1484\n",
      "Epoch 39/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 75396.7109\n",
      "Epoch 40/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 72992.9740\n",
      "Epoch 41/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 73435.2292\n",
      "Epoch 42/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 70945.4870\n",
      "Epoch 43/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 75212.8568\n",
      "Epoch 44/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 70377.9505\n",
      "Epoch 45/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 72886.0312\n",
      "Epoch 46/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 72508.8047\n",
      "Epoch 47/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 72252.7734\n",
      "Epoch 48/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 67895.2083\n",
      "Epoch 49/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 79570.8906\n",
      "Epoch 50/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 70567.4557\n",
      "Epoch 51/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 71020.8958\n",
      "Epoch 52/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 70788.3932\n",
      "Epoch 53/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 75426.3880\n",
      "Epoch 54/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 77182.8646\n",
      "Epoch 55/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 77751.6250\n",
      "Epoch 56/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 63430.8828\n",
      "Epoch 57/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 64412.6393\n",
      "Epoch 58/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 78988.8854\n",
      "Epoch 59/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 70548.4479\n",
      "Epoch 60/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 69415.2422\n",
      "Epoch 61/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 64629.1602\n",
      "Epoch 62/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 72177.4479\n",
      "Epoch 63/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 70826.0703\n",
      "Epoch 64/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 62018.9935\n",
      "Epoch 65/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 67319.0677\n",
      "Epoch 66/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 61640.9505\n",
      "Epoch 67/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 63540.6068\n",
      "Epoch 68/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 71336.1016\n",
      "Epoch 69/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 64383.4128\n",
      "Epoch 70/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 59930.3594\n",
      "Epoch 71/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 64586.1745\n",
      "Epoch 72/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 82104.6094\n",
      "Epoch 73/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 64649.8451\n",
      "Epoch 74/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 63178.8659\n",
      "Epoch 75/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 58090.1211\n",
      "Epoch 76/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 59763.0091\n",
      "Epoch 77/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 65945.0573\n",
      "Epoch 78/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 60629.5326\n",
      "Epoch 79/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 63766.6185\n",
      "Epoch 80/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 57884.3919\n",
      "Epoch 81/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 60961.1901\n",
      "Epoch 82/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 59096.1289\n",
      "Epoch 83/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 58659.0234\n",
      "Epoch 84/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 62268.9466\n",
      "Epoch 85/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 53319.0143\n",
      "Epoch 86/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 56114.7565\n",
      "Epoch 87/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 61225.6003\n",
      "Epoch 88/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 57462.7539\n",
      "Epoch 89/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 58310.2396\n",
      "Epoch 90/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 57898.7799\n",
      "Epoch 91/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 61711.4206\n",
      "Epoch 92/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 54321.5078\n",
      "Epoch 93/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 58887.7708\n",
      "Epoch 94/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 57729.6966\n",
      "Epoch 95/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 55528.9701\n",
      "Epoch 96/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 56233.4453\n",
      "Epoch 97/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49654.9323\n",
      "Epoch 98/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 53445.2995\n",
      "Epoch 99/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 62702.4883\n",
      "Epoch 100/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50955.2461\n",
      "Epoch 101/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 53958.0417\n",
      "Epoch 102/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 59390.1979\n",
      "Epoch 103/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 55318.4961\n",
      "Epoch 104/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 53518.8815\n",
      "Epoch 105/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 51651.3477\n",
      "Epoch 106/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 56565.4466\n",
      "Epoch 107/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 56521.9701\n",
      "Epoch 108/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 51156.8503\n",
      "Epoch 109/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50674.0039\n",
      "Epoch 110/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50125.9544\n",
      "Epoch 111/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 61076.4505\n",
      "Epoch 112/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 45654.1302\n",
      "Epoch 113/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 63824.2995\n",
      "Epoch 114/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 48094.1198\n",
      "Epoch 115/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 52289.2669\n",
      "Epoch 116/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 48190.4089\n",
      "Epoch 117/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 46353.8984\n",
      "Epoch 118/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49446.5872\n",
      "Epoch 119/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 51507.7917\n",
      "Epoch 120/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 46873.1198\n",
      "Epoch 121/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 51186.5690\n",
      "Epoch 122/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 48118.6042\n",
      "Epoch 123/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 54367.5495\n",
      "Epoch 124/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 46922.6549\n",
      "Epoch 125/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 52071.0807\n",
      "Epoch 126/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 46133.6562\n",
      "Epoch 127/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 44652.3164\n",
      "Epoch 128/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 43495.0573\n",
      "Epoch 129/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 54257.9661\n",
      "Epoch 130/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 46081.2357\n",
      "Epoch 131/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 51116.4375\n",
      "Epoch 132/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 46700.2982\n",
      "Epoch 133/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49167.1680\n",
      "Epoch 134/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 45234.9714\n",
      "Epoch 135/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 48889.5885\n",
      "Epoch 136/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 51025.4701\n",
      "Epoch 137/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 52368.7539\n",
      "Epoch 138/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 51555.0169\n",
      "Epoch 139/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 46761.0404\n",
      "Epoch 140/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 47068.5391\n",
      "Epoch 141/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 48124.8958\n",
      "Epoch 142/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 45030.1276\n",
      "Epoch 143/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 40444.4362\n",
      "Epoch 144/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 52371.4779\n",
      "Epoch 145/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 44051.0911\n",
      "Epoch 146/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 46344.9557\n",
      "Epoch 147/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 45246.0664\n",
      "Epoch 148/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 43729.2865\n",
      "Epoch 149/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 43515.3581\n",
      "Epoch 150/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 40886.3529\n",
      "Epoch 151/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 39431.7891\n",
      "Epoch 152/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 40500.7057\n",
      "Epoch 153/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 47069.4362\n",
      "Epoch 154/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 47524.9427\n",
      "Epoch 155/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 45428.8477\n",
      "Epoch 156/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 40011.2135\n",
      "Epoch 157/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 44342.7044\n",
      "Epoch 158/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 45865.1888\n",
      "Epoch 159/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 41308.1966\n",
      "Epoch 160/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 41018.3047\n",
      "Epoch 161/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49473.4219\n",
      "Epoch 162/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 42971.0299\n",
      "Epoch 163/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 39616.3763\n",
      "Epoch 164/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 50360.3906\n",
      "Epoch 165/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 43667.6211\n",
      "Epoch 166/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 49833.8164\n",
      "Epoch 167/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 47898.8711\n",
      "Epoch 168/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 39520.2161\n",
      "Epoch 169/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 41175.6289\n",
      "Epoch 170/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 40722.6667\n",
      "Epoch 171/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 34914.5026\n",
      "Epoch 172/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 47491.3099\n",
      "Epoch 173/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 37623.6549\n",
      "Epoch 174/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 40323.0521\n",
      "Epoch 175/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 41581.6458\n",
      "Epoch 176/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 41747.6107\n",
      "Epoch 177/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 41874.1523\n",
      "Epoch 178/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 42237.0508\n",
      "Epoch 179/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 38585.7552\n",
      "Epoch 180/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 41007.8802\n",
      "Epoch 181/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 42248.3958\n",
      "Epoch 182/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 39065.1172\n",
      "Epoch 183/187\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 42514.1393\n",
      "Epoch 184/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 36607.2617\n",
      "Epoch 185/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 39539.2214\n",
      "Epoch 186/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 38167.2539\n",
      "Epoch 187/187\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 36858.7552\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbe637c6670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "######### Test with the best hyperparameter combination\n",
    "adjusted_forecasts = test_model(best)\n",
    "adjusted_forecasts = pd.DataFrame(adjusted_forecasts)\n",
    "adjusted_forecasts.columns = df_bottom_phie_ts\n",
    "adjusted_forecasts = adjusted_forecasts.transpose()\n",
    "output_file_name = \"prison_arima/mse_ets2_forecasts_arima_prison_adjusted_fixed_forecasts_lambda_\" + str(best['reconciliation_loss_lambda']) + \".csv\"\n",
    "adjusted_forecasts.to_csv(output_file_name)\n",
    "\n",
    "best_config_df = pd.DataFrame(best)\n",
    "best_config_file_name = \"prison_arima/mse_ets2_forecasts_arima_best_config_fixed_lambda_\" + str(best['reconciliation_loss_lambda']) + \".csv\"\n",
    "best_config_df.to_csv(best_config_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b58ddb21",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "forecast = pd.read_csv('results/prison_arima_adjusted_forecasts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "28b6b0d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "forecast = forecast.set_index(forecast.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f680c738",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bottom_up_data = []\n",
    "start_index_bottom_ts = 57\n",
    "for key in all_indexes:\n",
    "    hf_index = key\n",
    "    low_ts = all_indexes[hf_index]\n",
    "    lower_index = low_ts[0] - start_index_bottom_ts  # finding the index value starting from 0\n",
    "    high_index = low_ts[-1] - start_index_bottom_ts\n",
    "    ts_data= forecast.iloc[lower_index:(high_index+1),:].sum(axis=0)\n",
    "    df = pd.DataFrame(ts_data)\n",
    "    df.columns = [df_actual_transpose.columns[key]]\n",
    "    bottom_up_data.append(df.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "439bb43a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aggregated</th>\n",
       "      <td>35431.646532</td>\n",
       "      <td>35709.197786</td>\n",
       "      <td>35646.477592</td>\n",
       "      <td>35850.194301</td>\n",
       "      <td>36083.373271</td>\n",
       "      <td>36241.774086</td>\n",
       "      <td>36248.998229</td>\n",
       "      <td>36420.609161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACT</th>\n",
       "      <td>393.915884</td>\n",
       "      <td>397.623853</td>\n",
       "      <td>398.565119</td>\n",
       "      <td>401.544859</td>\n",
       "      <td>405.458729</td>\n",
       "      <td>408.932634</td>\n",
       "      <td>410.758639</td>\n",
       "      <td>413.336842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NSW</th>\n",
       "      <td>10792.168220</td>\n",
       "      <td>10882.437400</td>\n",
       "      <td>10713.257690</td>\n",
       "      <td>10707.909820</td>\n",
       "      <td>10800.114600</td>\n",
       "      <td>10802.704700</td>\n",
       "      <td>10684.426665</td>\n",
       "      <td>10674.914400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NT</th>\n",
       "      <td>1632.832300</td>\n",
       "      <td>1654.347652</td>\n",
       "      <td>1672.210762</td>\n",
       "      <td>1693.040843</td>\n",
       "      <td>1713.915455</td>\n",
       "      <td>1734.196847</td>\n",
       "      <td>1753.309797</td>\n",
       "      <td>1773.456209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QLD</th>\n",
       "      <td>7331.407420</td>\n",
       "      <td>7336.911186</td>\n",
       "      <td>7332.868180</td>\n",
       "      <td>7342.316690</td>\n",
       "      <td>7354.159246</td>\n",
       "      <td>7341.325620</td>\n",
       "      <td>7328.457690</td>\n",
       "      <td>7325.508460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WA-Female-Sentenced-Non-ATSI</th>\n",
       "      <td>195.559110</td>\n",
       "      <td>197.986080</td>\n",
       "      <td>200.221570</td>\n",
       "      <td>202.817800</td>\n",
       "      <td>205.508880</td>\n",
       "      <td>208.168350</td>\n",
       "      <td>210.513930</td>\n",
       "      <td>213.089100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WA-Male-Remanded-ATSI</th>\n",
       "      <td>460.506230</td>\n",
       "      <td>477.339800</td>\n",
       "      <td>463.657100</td>\n",
       "      <td>468.938100</td>\n",
       "      <td>490.079860</td>\n",
       "      <td>506.626220</td>\n",
       "      <td>493.958600</td>\n",
       "      <td>499.272520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WA-Male-Remanded-Non-ATSI</th>\n",
       "      <td>659.332100</td>\n",
       "      <td>668.123900</td>\n",
       "      <td>676.656300</td>\n",
       "      <td>685.607600</td>\n",
       "      <td>694.659550</td>\n",
       "      <td>703.627200</td>\n",
       "      <td>712.292600</td>\n",
       "      <td>721.144960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WA-Male-Sentenced-ATSI</th>\n",
       "      <td>1448.802500</td>\n",
       "      <td>1449.383500</td>\n",
       "      <td>1449.492000</td>\n",
       "      <td>1450.143400</td>\n",
       "      <td>1451.066400</td>\n",
       "      <td>1451.845300</td>\n",
       "      <td>1452.100500</td>\n",
       "      <td>1452.713900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WA-Male-Sentenced-Non-ATSI</th>\n",
       "      <td>2394.521500</td>\n",
       "      <td>2404.016800</td>\n",
       "      <td>2408.311000</td>\n",
       "      <td>2411.079000</td>\n",
       "      <td>2412.862000</td>\n",
       "      <td>2414.007800</td>\n",
       "      <td>2414.347400</td>\n",
       "      <td>2414.912800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         0             1             2  \\\n",
       "Aggregated                    35431.646532  35709.197786  35646.477592   \n",
       "ACT                             393.915884    397.623853    398.565119   \n",
       "NSW                           10792.168220  10882.437400  10713.257690   \n",
       "NT                             1632.832300   1654.347652   1672.210762   \n",
       "QLD                            7331.407420   7336.911186   7332.868180   \n",
       "...                                    ...           ...           ...   \n",
       "WA-Female-Sentenced-Non-ATSI    195.559110    197.986080    200.221570   \n",
       "WA-Male-Remanded-ATSI           460.506230    477.339800    463.657100   \n",
       "WA-Male-Remanded-Non-ATSI       659.332100    668.123900    676.656300   \n",
       "WA-Male-Sentenced-ATSI         1448.802500   1449.383500   1449.492000   \n",
       "WA-Male-Sentenced-Non-ATSI     2394.521500   2404.016800   2408.311000   \n",
       "\n",
       "                                         3             4             5  \\\n",
       "Aggregated                    35850.194301  36083.373271  36241.774086   \n",
       "ACT                             401.544859    405.458729    408.932634   \n",
       "NSW                           10707.909820  10800.114600  10802.704700   \n",
       "NT                             1693.040843   1713.915455   1734.196847   \n",
       "QLD                            7342.316690   7354.159246   7341.325620   \n",
       "...                                    ...           ...           ...   \n",
       "WA-Female-Sentenced-Non-ATSI    202.817800    205.508880    208.168350   \n",
       "WA-Male-Remanded-ATSI           468.938100    490.079860    506.626220   \n",
       "WA-Male-Remanded-Non-ATSI       685.607600    694.659550    703.627200   \n",
       "WA-Male-Sentenced-ATSI         1450.143400   1451.066400   1451.845300   \n",
       "WA-Male-Sentenced-Non-ATSI     2411.079000   2412.862000   2414.007800   \n",
       "\n",
       "                                         6             7  \n",
       "Aggregated                    36248.998229  36420.609161  \n",
       "ACT                             410.758639    413.336842  \n",
       "NSW                           10684.426665  10674.914400  \n",
       "NT                             1753.309797   1773.456209  \n",
       "QLD                            7328.457690   7325.508460  \n",
       "...                                    ...           ...  \n",
       "WA-Female-Sentenced-Non-ATSI    210.513930    213.089100  \n",
       "WA-Male-Remanded-ATSI           493.958600    499.272520  \n",
       "WA-Male-Remanded-Non-ATSI       712.292600    721.144960  \n",
       "WA-Male-Sentenced-ATSI         1452.100500   1452.713900  \n",
       "WA-Male-Sentenced-Non-ATSI     2414.347400   2414.912800  \n",
       "\n",
       "[121 rows x 8 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(bottom_up_data).append(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3192a937",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}