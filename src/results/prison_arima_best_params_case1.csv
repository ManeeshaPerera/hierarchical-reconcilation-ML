,0
batch_size,25.0
dropout_rate,0.49859293944936484
epochs,81.0
layers,3
learning_rate,0.054971522141749565
max_norm_value,8.981328802385729
no_units_layer_4_1,136.0
no_units_layer_4_2,9.0
no_units_layer_4_3,68.0
no_units_layer_4_4,175.0
reconciliation_loss_lambda,0.36012046392829067
no_layers,4
no_units_layer,"[136, 9, 68, 175]"
