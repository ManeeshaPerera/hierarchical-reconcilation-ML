batch_size,dropout_rate,epochs,layers,learning_rate,max_norm_value,no_units_layer_4_1,no_units_layer_4_2,no_units_layer_4_3,no_units_layer_4_4,reconciliation_loss_lambda,no_layers,no_units_layer
4.0,0.13208466798310353,151.0,3,0.03918262459765832,2.3249445939038584,171.0,255.0,76.0,99.0,0.6095830970926421,4,171
4.0,0.13208466798310353,151.0,3,0.03918262459765832,2.3249445939038584,171.0,255.0,76.0,99.0,0.6095830970926421,4,255
4.0,0.13208466798310353,151.0,3,0.03918262459765832,2.3249445939038584,171.0,255.0,76.0,99.0,0.6095830970926421,4,76
4.0,0.13208466798310353,151.0,3,0.03918262459765832,2.3249445939038584,171.0,255.0,76.0,99.0,0.6095830970926421,4,99
