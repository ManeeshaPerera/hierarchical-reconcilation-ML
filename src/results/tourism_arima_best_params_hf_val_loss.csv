,0
batch_size,80.0
dropout_rate,0.45585445461155233
epochs,72.0
layers,0
learning_rate,0.005507022827253138
max_norm_value,4.217159818550043
no_units_layer_1_1,256.0
reconciliation_loss_lambda,0.2688817140489159
no_layers,1
no_units_layer,[256]
