,0
batch_size,12.0
dropout_rate,0.4613153092683441
epochs,172.0
layers,4
learning_rate,0.027695852141220573
max_norm_value,2.6436097639127274
no_units_layer_5_1,213.0
no_units_layer_5_2,228.0
no_units_layer_5_3,240.0
no_units_layer_5_4,197.0
no_units_layer_5_5,13.0
reconciliation_loss_lambda,0.779028269193059
no_layers,5
no_units_layer,"[213, 228, 240, 197, 13]"
