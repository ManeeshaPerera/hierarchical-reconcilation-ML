,0
batch_size,26.0
dropout_rate,0.38611209971743177
epochs,184.0
layers,2
learning_rate,0.06435571730377806
max_norm_value,4.5801159648081615
no_units_layer_3_1,86.0
no_units_layer_3_2,250.0
no_units_layer_3_3,81.0
reconciliation_loss_lambda,0.6943882481242349
no_layers,3
no_units_layer,"[86, 250, 81]"
