,0
batch_size,23.0
dropout_rate,0.3305247077043478
epochs,173.0
layers,2
learning_rate,0.08943985510821095
max_norm_value,9.985977304725091
no_units_layer_3_1,204.0
no_units_layer_3_2,185.0
no_units_layer_3_3,118.0
reconciliation_loss_lambda,0.2561829817897214
no_layers,3
no_units_layer,"[204, 185, 118]"
