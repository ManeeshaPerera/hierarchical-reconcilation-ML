batch_size,dropout_rate,epochs,layers,learning_rate,max_norm_value,no_units_layer_3_1,no_units_layer_3_2,no_units_layer_3_3,reconciliation_loss_lambda,no_layers,no_units_layer
6.0,0.26519243628362377,122.0,2,0.06633189676476281,3.4233392369026197,130.0,254.0,53.0,0.7086177387768957,3,130
6.0,0.26519243628362377,122.0,2,0.06633189676476281,3.4233392369026197,130.0,254.0,53.0,0.7086177387768957,3,254
6.0,0.26519243628362377,122.0,2,0.06633189676476281,3.4233392369026197,130.0,254.0,53.0,0.7086177387768957,3,53
