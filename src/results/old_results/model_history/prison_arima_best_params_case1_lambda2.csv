,0
batch_size,13.0
dropout_rate,0.3112856404131713
epochs,52.0
layers,4
learning_rate,0.06094195378376858
max_norm_value,2.221598112621659
no_units_layer_5_1,138.0
no_units_layer_5_2,21.0
no_units_layer_5_3,10.0
no_units_layer_5_4,146.0
no_units_layer_5_5,152.0
reconciliation_loss_lambda,2.509188497102113
no_layers,5
no_units_layer,"[138, 21, 10, 146, 152]"
