,0
batch_size,155.0
dropout_rate,0.1677321758859803
epochs,130.0
layers,4
learning_rate,0.09936145068929442
max_norm_value,1.772123198214116
no_units_layer_5_1,253.0
no_units_layer_5_2,238.0
no_units_layer_5_3,243.0
no_units_layer_5_4,245.0
no_units_layer_5_5,3.0
reconciliation_loss_lambda,0.05928567811995465
no_layers,5
no_units_layer,"[253, 238, 243, 245, 3]"
