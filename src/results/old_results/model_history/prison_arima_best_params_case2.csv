,0
batch_size,11.0
dropout_rate,0.17583011096034112
epochs,164.0
layers,3
learning_rate,0.0010409953623352203
max_norm_value,9.894081566337375
no_units_layer_4_1,133.0
no_units_layer_4_2,240.0
no_units_layer_4_3,144.0
no_units_layer_4_4,151.0
reconciliation_loss_lambda,0.08578554897925045
no_layers,4
no_units_layer,"[133, 240, 144, 151]"
