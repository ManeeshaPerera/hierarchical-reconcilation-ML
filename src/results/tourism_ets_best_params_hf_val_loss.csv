,0
batch_size,107.0
dropout_rate,0.34710362225867475
epochs,117.0
layers,2
learning_rate,0.009068467455268044
max_norm_value,2.9507114145741835
no_units_layer_3_1,188.0
no_units_layer_3_2,24.0
no_units_layer_3_3,6.0
reconciliation_loss_lambda,0.6784428275872236
no_layers,3
no_units_layer,"[188, 24, 6]"
