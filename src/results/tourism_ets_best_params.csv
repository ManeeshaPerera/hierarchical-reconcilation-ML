,0
batch_size,56.0
dropout_rate,0.34815652268300123
epochs,186.0
layers,3
learning_rate,0.0003753578376504349
max_norm_value,0.4078474293368375
no_units_layer_4_1,73.0
no_units_layer_4_2,252.0
no_units_layer_4_3,253.0
no_units_layer_4_4,11.0
reconciliation_loss_lambda,0.5827996167555797
no_layers,4
no_units_layer,"[73, 252, 253, 11]"
