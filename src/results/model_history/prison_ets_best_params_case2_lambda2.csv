,0
batch_size,10.0
dropout_rate,0.46105107938419476
epochs,86.0
layers,4
learning_rate,0.07085268146796989
max_norm_value,2.0929122365738433
no_units_layer_5_1,251.0
no_units_layer_5_2,249.0
no_units_layer_5_3,146.0
no_units_layer_5_4,162.0
no_units_layer_5_5,225.0
reconciliation_loss_lambda,4.9810241364852965
no_layers,5
no_units_layer,"[251, 249, 146, 162, 225]"
