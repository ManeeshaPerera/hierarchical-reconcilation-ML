,0
batch_size,8.0
dropout_rate,0.13706753511742673
epochs,142.0
layers,1
learning_rate,0.0004273824186223768
max_norm_value,0.08070178322306987
no_units_layer_2_1,83.0
no_units_layer_2_2,252.0
reconciliation_loss_lambda,0.09507888834625666
no_layers,2
no_units_layer,"[83, 252]"
