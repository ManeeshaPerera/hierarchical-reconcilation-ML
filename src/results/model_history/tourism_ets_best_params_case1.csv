,0
batch_size,49.0
dropout_rate,0.18358418223017456
epochs,152.0
layers,2
learning_rate,0.04416964711089361
max_norm_value,1.838389777399656
no_units_layer_3_1,22.0
no_units_layer_3_2,3.0
no_units_layer_3_3,217.0
reconciliation_loss_lambda,0.5705828457547004
no_layers,3
no_units_layer,"[22, 3, 217]"
