,0
batch_size,49.0
dropout_rate,0.4607782084551258
epochs,168.0
layers,3
learning_rate,0.0007650707120131564
max_norm_value,0.05989763282492255
no_units_layer_4_1,85.0
no_units_layer_4_2,173.0
no_units_layer_4_3,166.0
no_units_layer_4_4,4.0
reconciliation_loss_lambda,0.08209759571388768
no_layers,4
no_units_layer,"[85, 173, 166, 4]"
