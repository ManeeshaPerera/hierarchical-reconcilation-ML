,0
batch_size,181.0
dropout_rate,0.10326421231778571
epochs,112.0
layers,3
learning_rate,0.002952948562813795
max_norm_value,0.3492513890032356
no_units_layer_4_1,256.0
no_units_layer_4_2,214.0
no_units_layer_4_3,167.0
no_units_layer_4_4,156.0
reconciliation_loss_lambda,2.8531730539486304
no_layers,4
no_units_layer,"[256, 214, 167, 156]"
