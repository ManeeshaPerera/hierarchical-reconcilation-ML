,0
batch_size,22.0
dropout_rate,0.3643422213570058
epochs,89.0
layers,1
learning_rate,0.06160857405645728
max_norm_value,6.049100456187589
no_units_layer_2_1,225.0
no_units_layer_2_2,192.0
reconciliation_loss_lambda,1.2372922919938805
no_layers,2
no_units_layer,"[225, 192]"
