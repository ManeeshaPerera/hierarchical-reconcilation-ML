,0
batch_size,175.0
dropout_rate,0.15855384582592474
epochs,117.0
layers,1
learning_rate,0.0007122478592829599
max_norm_value,2.550305699192295
no_units_layer_2_1,237.0
no_units_layer_2_2,256.0
reconciliation_loss_lambda,0.5118083523110062
no_layers,2
no_units_layer,"[237, 256]"
