,0
batch_size,46.0
dropout_rate,0.11541341510725422
epochs,14.0
layers,1
learning_rate,0.015317250266380648
max_norm_value,8.539180596923703
no_units_layer_2_1,100.0
no_units_layer_2_2,253.0
reconciliation_loss_lambda,1.484248739370142
no_layers,2
no_units_layer,"[100, 253]"
