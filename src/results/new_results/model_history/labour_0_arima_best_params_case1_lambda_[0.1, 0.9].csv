,0
batch_size,15.0
dropout_rate,0.44459459155305914
epochs,164.0
layers,3
learning_rate,0.007970746907657054
max_norm_value,2.3678418154569574
no_units_layer_4_1,117.0
no_units_layer_4_2,105.0
no_units_layer_4_3,6.0
no_units_layer_4_4,135.0
reconciliation_loss_lambda,0.503749054801091
no_layers,4
no_units_layer,"[117, 105, 6, 135]"
