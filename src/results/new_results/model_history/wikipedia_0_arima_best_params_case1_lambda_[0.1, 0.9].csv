,0
batch_size,98.0
dropout_rate,0.13712659602203953
epochs,163.0
layers,4
learning_rate,0.0003230545614567085
max_norm_value,8.341646585351178
no_units_layer_5_1,39.0
no_units_layer_5_2,229.0
no_units_layer_5_3,46.0
no_units_layer_5_4,67.0
no_units_layer_5_5,146.0
reconciliation_loss_lambda,0.403320209062728
no_layers,5
no_units_layer,"[39, 229, 46, 67, 146]"
