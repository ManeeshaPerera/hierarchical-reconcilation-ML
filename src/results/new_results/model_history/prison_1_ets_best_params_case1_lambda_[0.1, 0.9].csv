,0
batch_size,11.0
dropout_rate,0.3322571277381763
epochs,52.0
layers,1
learning_rate,0.026371207656523753
max_norm_value,1.6116428244394378
no_units_layer_2_1,10.0
no_units_layer_2_2,182.0
reconciliation_loss_lambda,0.50870109708277
no_layers,2
no_units_layer,"[10, 182]"
