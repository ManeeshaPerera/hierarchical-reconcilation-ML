,0
batch_size,41.0
dropout_rate,0.2712752239669549
epochs,157.0
layers,1
learning_rate,0.002387718554237077
max_norm_value,0.8380404015852392
no_units_layer_2_1,168.0
no_units_layer_2_2,73.0
reconciliation_loss_lambda,4.294489674873087
no_layers,2
no_units_layer,"[168, 73]"
