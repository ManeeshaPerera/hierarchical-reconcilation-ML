,0
batch_size,40.0
dropout_rate,0.04324373928985699
epochs,26.0
layers,4
learning_rate,0.002741021387358219
max_norm_value,2.730665911168882
no_units_layer_5_1,4.0
no_units_layer_5_2,176.0
no_units_layer_5_3,161.0
no_units_layer_5_4,84.0
no_units_layer_5_5,12.0
reconciliation_loss_lambda,0.019627797533161306
no_layers,5
no_units_layer,"[4, 176, 161, 84, 12]"
