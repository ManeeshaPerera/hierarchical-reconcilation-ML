,0
batch_size,51.0
dropout_rate,0.1304869768167088
epochs,143.0
layers,3
learning_rate,0.01209521071347857
max_norm_value,1.2181717135833892
no_units_layer_4_1,125.0
no_units_layer_4_2,102.0
no_units_layer_4_3,6.0
no_units_layer_4_4,118.0
reconciliation_loss_lambda,0.03934427706339608
no_layers,4
no_units_layer,"[125, 102, 6, 118]"
