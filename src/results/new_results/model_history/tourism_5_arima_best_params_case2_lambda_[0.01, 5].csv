,0
batch_size,2.0
dropout_rate,0.1804337926901802
epochs,13.0
layers,3
learning_rate,0.014807212435869008
max_norm_value,8.367204226211584
no_units_layer_4_1,97.0
no_units_layer_4_2,102.0
no_units_layer_4_3,251.0
no_units_layer_4_4,88.0
reconciliation_loss_lambda,4.94539164643364
no_layers,4
no_units_layer,"[97, 102, 251, 88]"
