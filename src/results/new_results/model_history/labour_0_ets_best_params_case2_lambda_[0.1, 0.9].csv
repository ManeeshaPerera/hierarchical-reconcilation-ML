,0
batch_size,6.0
dropout_rate,0.3605487051813354
epochs,183.0
layers,3
learning_rate,0.033465116202606074
max_norm_value,7.284966993208614
no_units_layer_4_1,189.0
no_units_layer_4_2,37.0
no_units_layer_4_3,87.0
no_units_layer_4_4,192.0
reconciliation_loss_lambda,0.15142949064763941
no_layers,4
no_units_layer,"[189, 37, 87, 192]"
