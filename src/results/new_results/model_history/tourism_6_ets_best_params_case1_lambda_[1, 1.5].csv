,0
batch_size,64.0
dropout_rate,0.0010672929526591157
epochs,43.0
layers,3
learning_rate,0.09919021911511977
max_norm_value,0.08030637015864439
no_units_layer_4_1,244.0
no_units_layer_4_2,112.0
no_units_layer_4_3,59.0
no_units_layer_4_4,91.0
reconciliation_loss_lambda,1.4001819578047994
no_layers,4
no_units_layer,"[244, 112, 59, 91]"
