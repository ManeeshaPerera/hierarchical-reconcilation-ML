,0
batch_size,12.0
dropout_rate,0.433412403596843
epochs,192.0
layers,3
learning_rate,0.08971063378426139
max_norm_value,5.0668052350088635
no_units_layer_4_1,141.0
no_units_layer_4_2,153.0
no_units_layer_4_3,112.0
no_units_layer_4_4,175.0
reconciliation_loss_lambda,0.2539780542689031
no_layers,4
no_units_layer,"[141, 153, 112, 175]"
