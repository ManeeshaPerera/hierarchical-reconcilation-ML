,0
batch_size,55.0
dropout_rate,0.30163452475960995
epochs,42.0
layers,3
learning_rate,0.008387509585911519
max_norm_value,0.17927883692050192
no_units_layer_4_1,174.0
no_units_layer_4_2,8.0
no_units_layer_4_3,144.0
no_units_layer_4_4,237.0
reconciliation_loss_lambda,3.6661342807385373
no_layers,4
no_units_layer,"[174, 8, 144, 237]"
