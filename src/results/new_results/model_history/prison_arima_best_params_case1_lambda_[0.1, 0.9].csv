,0
batch_size,9.0
dropout_rate,0.18174862510799222
epochs,110.0
layers,3
learning_rate,0.002285436212144762
max_norm_value,6.9616399809996015
no_units_layer_4_1,10.0
no_units_layer_4_2,252.0
no_units_layer_4_3,243.0
no_units_layer_4_4,242.0
reconciliation_loss_lambda,0.5705828457547004
no_layers,4
no_units_layer,"[10, 252, 243, 242]"
