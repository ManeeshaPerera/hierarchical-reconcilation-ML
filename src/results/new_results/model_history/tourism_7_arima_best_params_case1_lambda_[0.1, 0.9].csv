,0
batch_size,60.0
dropout_rate,0.1823217856615807
epochs,125.0
layers,4
learning_rate,0.012942840817775898
max_norm_value,2.459427645649467
no_units_layer_5_1,16.0
no_units_layer_5_2,249.0
no_units_layer_5_3,254.0
no_units_layer_5_4,187.0
no_units_layer_5_5,168.0
reconciliation_loss_lambda,0.4347015081054896
no_layers,5
no_units_layer,"[16, 249, 254, 187, 168]"
