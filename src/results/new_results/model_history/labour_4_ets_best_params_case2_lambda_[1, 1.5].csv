,0
batch_size,14.0
dropout_rate,0.19326277489062668
epochs,12.0
layers,4
learning_rate,0.002933244640784559
max_norm_value,1.8301653009025287
no_units_layer_5_1,193.0
no_units_layer_5_2,254.0
no_units_layer_5_3,245.0
no_units_layer_5_4,215.0
no_units_layer_5_5,6.0
reconciliation_loss_lambda,1.299079888448389
no_layers,5
no_units_layer,"[193, 254, 245, 215, 6]"
