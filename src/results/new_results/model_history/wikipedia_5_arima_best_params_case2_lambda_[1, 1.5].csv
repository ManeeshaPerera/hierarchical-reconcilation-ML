,0
batch_size,142.0
dropout_rate,0.4653642239135299
epochs,11.0
layers,3
learning_rate,0.005890809343219357
max_norm_value,8.784993761788535
no_units_layer_4_1,125.0
no_units_layer_4_2,102.0
no_units_layer_4_3,6.0
no_units_layer_4_4,98.0
reconciliation_loss_lambda,1.4993035670255443
no_layers,4
no_units_layer,"[125, 102, 6, 98]"
