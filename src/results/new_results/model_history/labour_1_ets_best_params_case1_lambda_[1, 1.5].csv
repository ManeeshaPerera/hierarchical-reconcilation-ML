,0
batch_size,17.0
dropout_rate,0.39364073632088714
epochs,146.0
layers,3
learning_rate,0.001036949868442577
max_norm_value,7.857907957913308
no_units_layer_4_1,80.0
no_units_layer_4_2,151.0
no_units_layer_4_3,164.0
no_units_layer_4_4,85.0
reconciliation_loss_lambda,1.2474645639523054
no_layers,4
no_units_layer,"[80, 151, 164, 85]"
