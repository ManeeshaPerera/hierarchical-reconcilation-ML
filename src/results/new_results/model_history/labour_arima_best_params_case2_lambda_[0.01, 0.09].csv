,0
batch_size,49.0
dropout_rate,0.1595093073255257
epochs,118.0
layers,3
learning_rate,0.009322560610656738
max_norm_value,9.263806578948286
no_units_layer_4_1,118.0
no_units_layer_4_2,98.0
no_units_layer_4_3,8.0
no_units_layer_4_4,123.0
reconciliation_loss_lambda,0.021887562872021767
no_layers,4
no_units_layer,"[118, 98, 8, 123]"
