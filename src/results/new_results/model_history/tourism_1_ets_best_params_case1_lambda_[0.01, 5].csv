,0
batch_size,59.0
dropout_rate,0.05768712766152387
epochs,61.0
layers,1
learning_rate,0.06382924428854128
max_norm_value,0.8440431046708955
no_units_layer_2_1,1.0
no_units_layer_2_2,6.0
reconciliation_loss_lambda,3.7248069686606136
no_layers,2
no_units_layer,"[1, 6]"
