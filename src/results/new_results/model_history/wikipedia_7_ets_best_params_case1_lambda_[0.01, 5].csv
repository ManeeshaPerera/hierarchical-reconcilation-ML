,0
batch_size,90.0
dropout_rate,0.24244311188247675
epochs,88.0
layers,1
learning_rate,0.0003165786021814346
max_norm_value,6.2098435461624195
no_units_layer_2_1,168.0
no_units_layer_2_2,95.0
reconciliation_loss_lambda,4.3750088628673645
no_layers,2
no_units_layer,"[168, 95]"
