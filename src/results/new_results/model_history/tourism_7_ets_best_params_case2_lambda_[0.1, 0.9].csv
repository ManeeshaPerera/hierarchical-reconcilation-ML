,0
batch_size,32.0
dropout_rate,0.16873343280935188
epochs,45.0
layers,4
learning_rate,0.0166345347234547
max_norm_value,0.449136307000049
no_units_layer_5_1,205.0
no_units_layer_5_2,15.0
no_units_layer_5_3,7.0
no_units_layer_5_4,243.0
no_units_layer_5_5,2.0
reconciliation_loss_lambda,0.5837447032850707
no_layers,5
no_units_layer,"[205, 15, 7, 243, 2]"
