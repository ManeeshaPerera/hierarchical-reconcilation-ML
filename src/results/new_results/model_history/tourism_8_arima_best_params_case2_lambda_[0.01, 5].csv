,0
batch_size,111.0
dropout_rate,0.3915802169892488
epochs,145.0
layers,3
learning_rate,0.023193290040194072
max_norm_value,1.045836931045752
no_units_layer_4_1,164.0
no_units_layer_4_2,157.0
no_units_layer_4_3,161.0
no_units_layer_4_4,67.0
reconciliation_loss_lambda,3.73423236139887
no_layers,4
no_units_layer,"[164, 157, 161, 67]"
