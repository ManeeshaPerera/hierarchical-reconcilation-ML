,0
batch_size,56.0
dropout_rate,0.01894453577407057
epochs,107.0
layers,4
learning_rate,0.054870265962072784
max_norm_value,0.2640614102152329
no_units_layer_5_1,176.0
no_units_layer_5_2,14.0
no_units_layer_5_3,247.0
no_units_layer_5_4,186.0
no_units_layer_5_5,144.0
reconciliation_loss_lambda,3.869896175301146
no_layers,5
no_units_layer,"[176, 14, 247, 186, 144]"
