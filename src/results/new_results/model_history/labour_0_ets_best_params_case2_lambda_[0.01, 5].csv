,0
batch_size,46.0
dropout_rate,0.0706528175885851
epochs,166.0
layers,3
learning_rate,0.049376856340786986
max_norm_value,7.881802382204111
no_units_layer_4_1,122.0
no_units_layer_4_2,48.0
no_units_layer_4_3,46.0
no_units_layer_4_4,2.0
reconciliation_loss_lambda,0.4556277127984698
no_layers,4
no_units_layer,"[122, 48, 46, 2]"
