,0
batch_size,18.0
dropout_rate,0.3913005341216711
epochs,123.0
layers,4
learning_rate,0.015243296273572154
max_norm_value,4.277273707949192
no_units_layer_5_1,39.0
no_units_layer_5_2,8.0
no_units_layer_5_3,2.0
no_units_layer_5_4,212.0
no_units_layer_5_5,35.0
reconciliation_loss_lambda,1.3386297809443009
no_layers,5
no_units_layer,"[39, 8, 2, 212, 35]"
