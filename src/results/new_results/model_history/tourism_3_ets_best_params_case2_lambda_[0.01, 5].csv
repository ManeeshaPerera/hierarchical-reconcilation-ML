,0
batch_size,29.0
dropout_rate,0.214452200965473
epochs,103.0
layers,4
learning_rate,0.07979127093291864
max_norm_value,2.9846200427475984
no_units_layer_5_1,158.0
no_units_layer_5_2,163.0
no_units_layer_5_3,213.0
no_units_layer_5_4,67.0
no_units_layer_5_5,110.0
reconciliation_loss_lambda,4.514917637674739
no_layers,5
no_units_layer,"[158, 163, 213, 67, 110]"
