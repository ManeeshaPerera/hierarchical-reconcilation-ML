,0
batch_size,78.0
dropout_rate,0.34565151025443586
epochs,95.0
layers,1
learning_rate,0.0008302147220261112
max_norm_value,6.269207966076168
no_units_layer_2_1,93.0
no_units_layer_2_2,88.0
reconciliation_loss_lambda,0.6784184817995162
no_layers,2
no_units_layer,"[93, 88]"
