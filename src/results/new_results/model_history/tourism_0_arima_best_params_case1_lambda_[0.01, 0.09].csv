,0
batch_size,88.0
dropout_rate,0.1855681766735449
epochs,127.0
layers,4
learning_rate,0.047038184569390434
max_norm_value,4.214069961398597
no_units_layer_5_1,7.0
no_units_layer_5_2,115.0
no_units_layer_5_3,111.0
no_units_layer_5_4,121.0
no_units_layer_5_5,161.0
reconciliation_loss_lambda,0.0551320921360801
no_layers,5
no_units_layer,"[7, 115, 111, 121, 161]"
