,0
batch_size,2.0
dropout_rate,0.14833674719496304
epochs,167.0
layers,4
learning_rate,0.001584042183652469
max_norm_value,3.773544480434152
no_units_layer_5_1,231.0
no_units_layer_5_2,250.0
no_units_layer_5_3,222.0
no_units_layer_5_4,232.0
no_units_layer_5_5,252.0
reconciliation_loss_lambda,1.0601735581060447
no_layers,5
no_units_layer,"[231, 250, 222, 232, 252]"
