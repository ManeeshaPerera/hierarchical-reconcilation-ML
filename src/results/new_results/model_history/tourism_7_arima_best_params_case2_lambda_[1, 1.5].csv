,0
batch_size,31.0
dropout_rate,0.3194653878621387
epochs,43.0
layers,1
learning_rate,0.004383669308447887
max_norm_value,2.723868251382404
no_units_layer_2_1,247.0
no_units_layer_2_2,76.0
reconciliation_loss_lambda,1.4606402827007992
no_layers,2
no_units_layer,"[247, 76]"
