,0
batch_size,40.0
dropout_rate,0.19717193702447894
epochs,16.0
layers,4
learning_rate,0.0009446314379910892
max_norm_value,1.5705871595808854
no_units_layer_5_1,207.0
no_units_layer_5_2,218.0
no_units_layer_5_3,88.0
no_units_layer_5_4,141.0
no_units_layer_5_5,184.0
reconciliation_loss_lambda,0.023836277994552242
no_layers,5
no_units_layer,"[207, 218, 88, 141, 184]"
