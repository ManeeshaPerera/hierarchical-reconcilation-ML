,0
batch_size,75.0
dropout_rate,0.07910695100229587
epochs,187.0
layers,2
learning_rate,0.06157509611481259
max_norm_value,1.0556209820811446
no_units_layer_3_1,220.0
no_units_layer_3_2,86.0
no_units_layer_3_3,53.0
reconciliation_loss_lambda,0.8001980873193181
no_layers,3
no_units_layer,"[220, 86, 53]"
