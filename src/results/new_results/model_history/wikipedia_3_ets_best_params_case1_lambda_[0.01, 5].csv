,0
batch_size,73.0
dropout_rate,0.3509851090216197
epochs,92.0
layers,1
learning_rate,0.0008258053532916072
max_norm_value,3.07229153082158
no_units_layer_2_1,175.0
no_units_layer_2_2,107.0
reconciliation_loss_lambda,1.6605547821414466
no_layers,2
no_units_layer,"[175, 107]"
