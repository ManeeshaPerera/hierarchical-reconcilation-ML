,0
batch_size,23.0
dropout_rate,0.13706753511742673
epochs,158.0
layers,1
learning_rate,0.00047886890463806446
max_norm_value,9.447674366674018
no_units_layer_2_1,252.0
no_units_layer_2_2,4.0
reconciliation_loss_lambda,0.08944749607260143
no_layers,2
no_units_layer,"[252, 4]"
