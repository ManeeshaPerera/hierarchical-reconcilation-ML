,0
batch_size,70.0
dropout_rate,0.2831658690828577
epochs,82.0
layers,3
learning_rate,0.02403341920714646
max_norm_value,1.5977008131102002
no_units_layer_4_1,174.0
no_units_layer_4_2,113.0
no_units_layer_4_3,226.0
no_units_layer_4_4,89.0
reconciliation_loss_lambda,1.1939623231935728
no_layers,4
no_units_layer,"[174, 113, 226, 89]"
