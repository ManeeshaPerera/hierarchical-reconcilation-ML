,0
batch_size,247.0
dropout_rate,0.3114551728646267
epochs,157.0
layers,3
learning_rate,0.0007392032571720308
max_norm_value,3.319239032297566
no_units_layer_4_1,142.0
no_units_layer_4_2,124.0
no_units_layer_4_3,246.0
no_units_layer_4_4,137.0
reconciliation_loss_lambda,0.11659979704925005
no_layers,4
no_units_layer,"[142, 124, 246, 137]"
