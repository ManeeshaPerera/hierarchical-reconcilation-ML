,0
batch_size,18.0
dropout_rate,0.2766680451298397
epochs,45.0
layers,4
learning_rate,0.00014959417077411996
max_norm_value,0.3779680863552113
no_units_layer_5_1,3.0
no_units_layer_5_2,172.0
no_units_layer_5_3,241.0
no_units_layer_5_4,194.0
no_units_layer_5_5,58.0
reconciliation_loss_lambda,0.05457956745792411
no_layers,5
no_units_layer,"[3, 172, 241, 194, 58]"
