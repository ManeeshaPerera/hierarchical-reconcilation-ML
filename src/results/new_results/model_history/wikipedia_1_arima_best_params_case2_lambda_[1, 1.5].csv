,0
batch_size,37.0
dropout_rate,0.2880538020508521
epochs,82.0
layers,1
learning_rate,0.00027381130497213776
max_norm_value,5.28690268796477
no_units_layer_2_1,100.0
no_units_layer_2_2,90.0
reconciliation_loss_lambda,1.0544903876476683
no_layers,2
no_units_layer,"[100, 90]"
