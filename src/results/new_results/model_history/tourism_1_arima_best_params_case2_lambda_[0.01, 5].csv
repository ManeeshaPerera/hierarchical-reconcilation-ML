,0
batch_size,55.0
dropout_rate,0.2085810741818213
epochs,115.0
layers,4
learning_rate,0.03353566365084325
max_norm_value,0.4857158441194941
no_units_layer_5_1,214.0
no_units_layer_5_2,210.0
no_units_layer_5_3,152.0
no_units_layer_5_4,32.0
no_units_layer_5_5,207.0
reconciliation_loss_lambda,3.842735333361645
no_layers,5
no_units_layer,"[214, 210, 152, 32, 207]"
