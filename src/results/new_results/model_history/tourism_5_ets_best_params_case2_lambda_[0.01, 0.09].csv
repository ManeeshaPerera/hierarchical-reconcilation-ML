,0
batch_size,63.0
dropout_rate,0.23165061327942268
epochs,81.0
layers,1
learning_rate,0.007060640928052458
max_norm_value,3.659603184256359
no_units_layer_2_1,252.0
no_units_layer_2_2,12.0
reconciliation_loss_lambda,0.02361294588464172
no_layers,2
no_units_layer,"[252, 12]"
