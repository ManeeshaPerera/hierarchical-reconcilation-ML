,0
batch_size,106.0
dropout_rate,0.34201481294366903
epochs,135.0
layers,0
learning_rate,0.03499158315272582
max_norm_value,4.1716268818537365
no_units_layer_1_1,34.0
reconciliation_loss_lambda,0.2961708391046929
no_layers,1
no_units_layer,[34]
