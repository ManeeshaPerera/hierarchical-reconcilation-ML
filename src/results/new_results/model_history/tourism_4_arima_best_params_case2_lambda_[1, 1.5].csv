,0
batch_size,101.0
dropout_rate,0.35693566382048486
epochs,145.0
layers,3
learning_rate,0.011180664010710495
max_norm_value,2.441712645485948
no_units_layer_4_1,120.0
no_units_layer_4_2,248.0
no_units_layer_4_3,255.0
no_units_layer_4_4,125.0
reconciliation_loss_lambda,1.2023777761548209
no_layers,4
no_units_layer,"[120, 248, 255, 125]"
