,0
batch_size,146.0
dropout_rate,0.42626973844281907
epochs,84.0
layers,1
learning_rate,0.0008234600854297845
max_norm_value,3.602294262519484
no_units_layer_2_1,167.0
no_units_layer_2_2,221.0
reconciliation_loss_lambda,1.9984231121175218
no_layers,2
no_units_layer,"[167, 221]"
