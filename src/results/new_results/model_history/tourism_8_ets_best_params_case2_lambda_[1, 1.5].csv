,0
batch_size,98.0
dropout_rate,0.05377651177516074
epochs,88.0
layers,3
learning_rate,0.007885302265041687
max_norm_value,0.009352351918473834
no_units_layer_4_1,90.0
no_units_layer_4_2,241.0
no_units_layer_4_3,254.0
no_units_layer_4_4,157.0
reconciliation_loss_lambda,1.4624133697865134
no_layers,4
no_units_layer,"[90, 241, 254, 157]"
