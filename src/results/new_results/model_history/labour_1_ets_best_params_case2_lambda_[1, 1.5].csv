,0
batch_size,28.0
dropout_rate,0.14391084780060107
epochs,21.0
layers,4
learning_rate,0.0003130923609508061
max_norm_value,6.49861051533203
no_units_layer_5_1,193.0
no_units_layer_5_2,176.0
no_units_layer_5_3,175.0
no_units_layer_5_4,1.0
no_units_layer_5_5,93.0
reconciliation_loss_lambda,1.0003343712631216
no_layers,5
no_units_layer,"[193, 176, 175, 1, 93]"
