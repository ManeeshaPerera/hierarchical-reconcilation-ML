,0
batch_size,12.0
dropout_rate,0.3032708482701043
epochs,155.0
layers,4
learning_rate,0.03627690333243497
max_norm_value,6.374972400101222
no_units_layer_5_1,233.0
no_units_layer_5_2,247.0
no_units_layer_5_3,211.0
no_units_layer_5_4,247.0
no_units_layer_5_5,252.0
reconciliation_loss_lambda,1.3545598696804941
no_layers,5
no_units_layer,"[233, 247, 211, 247, 252]"
