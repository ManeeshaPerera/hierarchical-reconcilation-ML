,0
batch_size,5.0
dropout_rate,0.23379502892591034
epochs,118.0
layers,1
learning_rate,0.04678991820603623
max_norm_value,3.5640033645596754
no_units_layer_2_1,161.0
no_units_layer_2_2,201.0
reconciliation_loss_lambda,0.049537678427667556
no_layers,2
no_units_layer,"[161, 201]"
