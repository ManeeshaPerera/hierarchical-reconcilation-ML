,0
batch_size,110.0
dropout_rate,0.06650727344970332
epochs,51.0
layers,1
learning_rate,0.0036745911075836343
max_norm_value,1.4900057866984164
no_units_layer_2_1,203.0
no_units_layer_2_2,65.0
reconciliation_loss_lambda,0.07666741836530624
no_layers,2
no_units_layer,"[203, 65]"
