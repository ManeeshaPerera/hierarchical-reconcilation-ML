,0
batch_size,40.0
dropout_rate,0.2561617756824816
epochs,62.0
layers,3
learning_rate,0.04779071652941816
max_norm_value,0.639930284864095
no_units_layer_4_1,149.0
no_units_layer_4_2,178.0
no_units_layer_4_3,21.0
no_units_layer_4_4,169.0
reconciliation_loss_lambda,1.6861286450189863
no_layers,4
no_units_layer,"[149, 178, 21, 169]"
