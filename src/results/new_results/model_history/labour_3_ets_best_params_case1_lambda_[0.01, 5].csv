,0
batch_size,43.0
dropout_rate,0.2726553199690021
epochs,38.0
layers,4
learning_rate,0.00028854071284807603
max_norm_value,1.5514705309239631
no_units_layer_5_1,66.0
no_units_layer_5_2,171.0
no_units_layer_5_3,106.0
no_units_layer_5_4,130.0
no_units_layer_5_5,116.0
reconciliation_loss_lambda,4.813201506890486
no_layers,5
no_units_layer,"[66, 171, 106, 130, 116]"
