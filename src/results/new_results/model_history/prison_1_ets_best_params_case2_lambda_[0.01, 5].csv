,0
batch_size,15.0
dropout_rate,0.2960584238293637
epochs,55.0
layers,3
learning_rate,0.0147554939333686
max_norm_value,0.8917532642620193
no_units_layer_4_1,8.0
no_units_layer_4_2,18.0
no_units_layer_4_3,255.0
no_units_layer_4_4,218.0
reconciliation_loss_lambda,1.6726510794752474
no_layers,4
no_units_layer,"[8, 18, 255, 218]"
