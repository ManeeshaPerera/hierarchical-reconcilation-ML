,0
batch_size,193.0
dropout_rate,0.4854161760580831
epochs,81.0
layers,4
learning_rate,0.0016632567915513964
max_norm_value,3.384083997863003
no_units_layer_5_1,185.0
no_units_layer_5_2,24.0
no_units_layer_5_3,200.0
no_units_layer_5_4,51.0
no_units_layer_5_5,82.0
reconciliation_loss_lambda,3.769827439863318
no_layers,5
no_units_layer,"[185, 24, 200, 51, 82]"
