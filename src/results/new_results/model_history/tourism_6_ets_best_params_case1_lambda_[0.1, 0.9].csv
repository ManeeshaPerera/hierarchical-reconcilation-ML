,0
batch_size,14.0
dropout_rate,0.38781316763789203
epochs,170.0
layers,4
learning_rate,0.03992552197697206
max_norm_value,2.6177975897523256
no_units_layer_5_1,200.0
no_units_layer_5_2,141.0
no_units_layer_5_3,149.0
no_units_layer_5_4,172.0
no_units_layer_5_5,47.0
reconciliation_loss_lambda,0.7866654669565372
no_layers,5
no_units_layer,"[200, 141, 149, 172, 47]"
