,0
batch_size,133.0
dropout_rate,0.20843345579060044
epochs,123.0
layers,3
learning_rate,0.001757210844123086
max_norm_value,8.004914327401876
no_units_layer_4_1,243.0
no_units_layer_4_2,8.0
no_units_layer_4_3,12.0
no_units_layer_4_4,39.0
reconciliation_loss_lambda,0.08847119900555869
no_layers,4
no_units_layer,"[243, 8, 12, 39]"
