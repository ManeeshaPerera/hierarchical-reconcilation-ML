,0
batch_size,3.0
dropout_rate,0.13832462646356425
epochs,43.0
layers,4
learning_rate,0.04069972905986868
max_norm_value,0.08731617636269817
no_units_layer_5_1,242.0
no_units_layer_5_2,249.0
no_units_layer_5_3,254.0
no_units_layer_5_4,16.0
no_units_layer_5_5,9.0
reconciliation_loss_lambda,0.8984552933781753
no_layers,5
no_units_layer,"[242, 249, 254, 16, 9]"
