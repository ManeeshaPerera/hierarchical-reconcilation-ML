,0
batch_size,2.0
dropout_rate,0.42293320351235164
epochs,125.0
layers,1
learning_rate,0.005248071743200366
max_norm_value,4.074943524489107
no_units_layer_2_1,116.0
no_units_layer_2_2,78.0
reconciliation_loss_lambda,3.3887250740590105
no_layers,2
no_units_layer,"[116, 78]"
