,0
batch_size,38.0
dropout_rate,0.4619754737090436
epochs,157.0
layers,1
learning_rate,0.015790011515125303
max_norm_value,2.017167079277801
no_units_layer_2_1,201.0
no_units_layer_2_2,104.0
reconciliation_loss_lambda,0.06362344278249607
no_layers,2
no_units_layer,"[201, 104]"
