,0
batch_size,2.0
dropout_rate,0.04940356432530915
epochs,140.0
layers,4
learning_rate,0.00798001179041172
max_norm_value,0.9874049458804053
no_units_layer_5_1,235.0
no_units_layer_5_2,247.0
no_units_layer_5_3,224.0
no_units_layer_5_4,238.0
no_units_layer_5_5,252.0
reconciliation_loss_lambda,1.3258588100493816
no_layers,5
no_units_layer,"[235, 247, 224, 238, 252]"
