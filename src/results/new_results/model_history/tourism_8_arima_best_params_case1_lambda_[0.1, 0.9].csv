,0
batch_size,2.0
dropout_rate,0.14347634185561314
epochs,164.0
layers,4
learning_rate,0.0922053068519714
max_norm_value,0.04025931905021807
no_units_layer_5_1,204.0
no_units_layer_5_2,186.0
no_units_layer_5_3,208.0
no_units_layer_5_4,65.0
no_units_layer_5_5,56.0
reconciliation_loss_lambda,0.636390545577401
no_layers,5
no_units_layer,"[204, 186, 208, 65, 56]"
