,0
batch_size,98.0
dropout_rate,0.05302493822884813
epochs,198.0
layers,1
learning_rate,0.037883547569687905
max_norm_value,0.37737726908460856
no_units_layer_2_1,256.0
no_units_layer_2_2,253.0
reconciliation_loss_lambda,1.1364331515548565
no_layers,2
no_units_layer,"[256, 253]"
