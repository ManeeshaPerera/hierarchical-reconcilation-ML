,0
batch_size,126.0
dropout_rate,0.0953451793602329
epochs,178.0
layers,1
learning_rate,0.0003557029254359801
max_norm_value,5.512716834543712
no_units_layer_2_1,107.0
no_units_layer_2_2,150.0
reconciliation_loss_lambda,3.5539825687392153
no_layers,2
no_units_layer,"[107, 150]"
