,0
batch_size,97.0
dropout_rate,0.21854616693273812
epochs,91.0
layers,3
learning_rate,0.0024674289729959883
max_norm_value,6.550371447588084
no_units_layer_4_1,243.0
no_units_layer_4_2,14.0
no_units_layer_4_3,12.0
no_units_layer_4_4,11.0
reconciliation_loss_lambda,0.0511032773760004
no_layers,4
no_units_layer,"[243, 14, 12, 11]"
