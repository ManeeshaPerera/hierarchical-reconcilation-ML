,0
batch_size,39.0
dropout_rate,0.22525624402484823
epochs,51.0
layers,3
learning_rate,0.008754209471243968
max_norm_value,1.3837120045142162
no_units_layer_4_1,125.0
no_units_layer_4_2,250.0
no_units_layer_4_3,48.0
no_units_layer_4_4,5.0
reconciliation_loss_lambda,4.614882368403971
no_layers,4
no_units_layer,"[125, 250, 48, 5]"
