,0
batch_size,53.0
dropout_rate,0.46209424181800896
epochs,89.0
layers,3
learning_rate,0.000847795022849256
max_norm_value,2.178323250222486
no_units_layer_4_1,247.0
no_units_layer_4_2,9.0
no_units_layer_4_3,2.0
no_units_layer_4_4,9.0
reconciliation_loss_lambda,0.06434657783978005
no_layers,4
no_units_layer,"[247, 9, 2, 9]"
