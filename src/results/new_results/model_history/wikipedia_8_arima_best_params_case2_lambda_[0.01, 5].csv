,0
batch_size,161.0
dropout_rate,0.4143254190654506
epochs,184.0
layers,4
learning_rate,0.0004519315678846104
max_norm_value,2.8662127184679154
no_units_layer_5_1,216.0
no_units_layer_5_2,169.0
no_units_layer_5_3,171.0
no_units_layer_5_4,12.0
no_units_layer_5_5,143.0
reconciliation_loss_lambda,3.0320036242383277
no_layers,5
no_units_layer,"[216, 169, 171, 12, 143]"
