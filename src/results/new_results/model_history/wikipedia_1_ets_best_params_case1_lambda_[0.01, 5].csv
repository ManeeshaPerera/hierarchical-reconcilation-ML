,0
batch_size,89.0
dropout_rate,0.021282797125518033
epochs,123.0
layers,3
learning_rate,0.00016789264538740657
max_norm_value,6.552307718271513
no_units_layer_4_1,190.0
no_units_layer_4_2,133.0
no_units_layer_4_3,24.0
no_units_layer_4_4,254.0
reconciliation_loss_lambda,1.712224835328164
no_layers,4
no_units_layer,"[190, 133, 24, 254]"
