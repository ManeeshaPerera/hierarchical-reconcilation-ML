,0
batch_size,9.0
dropout_rate,0.2074745247647391
epochs,18.0
layers,3
learning_rate,0.0005474537963607827
max_norm_value,5.4597209890498215
no_units_layer_4_1,228.0
no_units_layer_4_2,89.0
no_units_layer_4_3,74.0
no_units_layer_4_4,237.0
reconciliation_loss_lambda,2.171728258470297
no_layers,4
no_units_layer,"[228, 89, 74, 237]"
