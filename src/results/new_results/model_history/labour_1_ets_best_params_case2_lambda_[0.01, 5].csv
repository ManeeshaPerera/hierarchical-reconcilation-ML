,0
batch_size,53.0
dropout_rate,0.47075569369261483
epochs,142.0
layers,3
learning_rate,0.0002334861371688715
max_norm_value,2.4585991552079673
no_units_layer_4_1,123.0
no_units_layer_4_2,109.0
no_units_layer_4_3,84.0
no_units_layer_4_4,111.0
reconciliation_loss_lambda,2.460052773252586
no_layers,4
no_units_layer,"[123, 109, 84, 111]"
