,0
batch_size,33.0
dropout_rate,0.21601982098636724
epochs,89.0
layers,4
learning_rate,0.07397755502174856
max_norm_value,2.98989910885434
no_units_layer_5_1,4.0
no_units_layer_5_2,126.0
no_units_layer_5_3,131.0
no_units_layer_5_4,3.0
no_units_layer_5_5,48.0
reconciliation_loss_lambda,0.761138841492343
no_layers,5
no_units_layer,"[4, 126, 131, 3, 48]"
