,0
batch_size,8.0
dropout_rate,0.4893461583760476
epochs,90.0
layers,4
learning_rate,0.00036409755349106046
max_norm_value,6.497112813629769
no_units_layer_5_1,234.0
no_units_layer_5_2,246.0
no_units_layer_5_3,250.0
no_units_layer_5_4,4.0
no_units_layer_5_5,2.0
reconciliation_loss_lambda,0.06227374264873646
no_layers,5
no_units_layer,"[234, 246, 250, 4, 2]"
