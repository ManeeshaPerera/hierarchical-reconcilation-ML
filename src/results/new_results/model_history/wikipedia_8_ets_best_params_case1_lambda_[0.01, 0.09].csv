,0
batch_size,73.0
dropout_rate,0.4939608776698581
epochs,92.0
layers,3
learning_rate,0.0017946671649136674
max_norm_value,1.7546686625239891
no_units_layer_4_1,249.0
no_units_layer_4_2,12.0
no_units_layer_4_3,24.0
no_units_layer_4_4,11.0
reconciliation_loss_lambda,0.07906338292760355
no_layers,4
no_units_layer,"[249, 12, 24, 11]"
