,0
batch_size,36.0
dropout_rate,9.664644892157237e-05
epochs,26.0
layers,4
learning_rate,0.0002647674720602806
max_norm_value,0.7432283096354535
no_units_layer_5_1,150.0
no_units_layer_5_2,157.0
no_units_layer_5_3,151.0
no_units_layer_5_4,254.0
no_units_layer_5_5,165.0
reconciliation_loss_lambda,2.7594582148635047
no_layers,5
no_units_layer,"[150, 157, 151, 254, 165]"
