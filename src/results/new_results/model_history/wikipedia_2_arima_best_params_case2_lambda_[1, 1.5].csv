,0
batch_size,56.0
dropout_rate,0.36196475632121106
epochs,75.0
layers,0
learning_rate,0.0002721067934372519
max_norm_value,5.025915945487205
no_units_layer_1_1,96.0
reconciliation_loss_lambda,1.198829501504873
no_layers,1
no_units_layer,[96]
