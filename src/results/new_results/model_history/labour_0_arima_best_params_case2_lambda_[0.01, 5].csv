,0
batch_size,20.0
dropout_rate,0.4752807555209987
epochs,197.0
layers,1
learning_rate,0.0025526439033167307
max_norm_value,9.794297964267805
no_units_layer_2_1,26.0
no_units_layer_2_2,105.0
reconciliation_loss_lambda,2.310783097935998
no_layers,2
no_units_layer,"[26, 105]"
