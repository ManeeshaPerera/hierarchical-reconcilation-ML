,0
batch_size,36.0
dropout_rate,0.12320006733644631
epochs,153.0
layers,1
learning_rate,0.00044165063228841767
max_norm_value,7.901248515555862
no_units_layer_2_1,235.0
no_units_layer_2_2,93.0
reconciliation_loss_lambda,3.800950921034816
no_layers,2
no_units_layer,"[235, 93]"
