,0
batch_size,108.0
dropout_rate,0.21199625777020165
epochs,16.0
layers,4
learning_rate,0.0415847209773054
max_norm_value,0.12138488542120163
no_units_layer_5_1,251.0
no_units_layer_5_2,251.0
no_units_layer_5_3,214.0
no_units_layer_5_4,25.0
no_units_layer_5_5,21.0
reconciliation_loss_lambda,1.314100782604933
no_layers,5
no_units_layer,"[251, 251, 214, 25, 21]"
