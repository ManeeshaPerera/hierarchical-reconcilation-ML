,0
batch_size,55.0
dropout_rate,0.15007677316825133
epochs,97.0
layers,3
learning_rate,0.0018316805699415844
max_norm_value,3.849907834274022
no_units_layer_4_1,117.0
no_units_layer_4_2,61.0
no_units_layer_4_3,69.0
no_units_layer_4_4,17.0
reconciliation_loss_lambda,3.9418510100229427
no_layers,4
no_units_layer,"[117, 61, 69, 17]"
