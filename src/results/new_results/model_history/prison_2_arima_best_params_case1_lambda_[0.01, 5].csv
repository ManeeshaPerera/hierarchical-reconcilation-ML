,0
batch_size,7.0
dropout_rate,0.48307381204357525
epochs,55.0
layers,3
learning_rate,0.05723957373564583
max_norm_value,5.177801722498485
no_units_layer_4_1,225.0
no_units_layer_4_2,141.0
no_units_layer_4_3,31.0
no_units_layer_4_4,182.0
reconciliation_loss_lambda,0.5204443460578985
no_layers,4
no_units_layer,"[225, 141, 31, 182]"
