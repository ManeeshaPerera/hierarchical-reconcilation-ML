,0
batch_size,63.0
dropout_rate,0.12272355627184361
epochs,25.0
layers,1
learning_rate,0.027547647218613316
max_norm_value,3.8168525564165545
no_units_layer_2_1,248.0
no_units_layer_2_2,2.0
reconciliation_loss_lambda,0.08523114984441002
no_layers,2
no_units_layer,"[248, 2]"
