,0
batch_size,41.0
dropout_rate,0.49857334275739484
epochs,150.0
layers,4
learning_rate,0.014044860614213523
max_norm_value,2.0197188311784133
no_units_layer_5_1,115.0
no_units_layer_5_2,11.0
no_units_layer_5_3,168.0
no_units_layer_5_4,46.0
no_units_layer_5_5,138.0
reconciliation_loss_lambda,0.05411141494881973
no_layers,5
no_units_layer,"[115, 11, 168, 46, 138]"
