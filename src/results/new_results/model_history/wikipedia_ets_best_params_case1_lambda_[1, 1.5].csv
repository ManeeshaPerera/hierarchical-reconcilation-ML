,0
batch_size,102.0
dropout_rate,0.22341272248913666
epochs,91.0
layers,3
learning_rate,0.0009901850742188181
max_norm_value,4.364263939934702
no_units_layer_4_1,139.0
no_units_layer_4_2,99.0
no_units_layer_4_3,4.0
no_units_layer_4_4,89.0
reconciliation_loss_lambda,1.3260897867846337
no_layers,4
no_units_layer,"[139, 99, 4, 89]"
