,0
batch_size,70.0
dropout_rate,0.1779685466319356
epochs,26.0
layers,4
learning_rate,0.0012443136367785287
max_norm_value,2.0686244239587106
no_units_layer_5_1,15.0
no_units_layer_5_2,251.0
no_units_layer_5_3,248.0
no_units_layer_5_4,3.0
no_units_layer_5_5,256.0
reconciliation_loss_lambda,1.2941142785966877
no_layers,5
no_units_layer,"[15, 251, 248, 3, 256]"
