,0
batch_size,83.0
dropout_rate,0.15017960231712715
epochs,128.0
layers,4
learning_rate,0.09744342046618747
max_norm_value,0.16705332182926555
no_units_layer_5_1,253.0
no_units_layer_5_2,250.0
no_units_layer_5_3,254.0
no_units_layer_5_4,6.0
no_units_layer_5_5,6.0
reconciliation_loss_lambda,0.896107515176471
no_layers,5
no_units_layer,"[253, 250, 254, 6, 6]"
