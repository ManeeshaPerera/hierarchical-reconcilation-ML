,0
batch_size,9.0
dropout_rate,0.4762101587550813
epochs,152.0
layers,3
learning_rate,0.044880581185338955
max_norm_value,4.219934755515212
no_units_layer_4_1,95.0
no_units_layer_4_2,82.0
no_units_layer_4_3,12.0
no_units_layer_4_4,95.0
reconciliation_loss_lambda,0.08970524051131562
no_layers,4
no_units_layer,"[95, 82, 12, 95]"
