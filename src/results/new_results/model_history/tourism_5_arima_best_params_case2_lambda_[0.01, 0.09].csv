,0
batch_size,64.0
dropout_rate,0.21807490645456104
epochs,118.0
layers,0
learning_rate,0.0004690825637867612
max_norm_value,6.297238077473282
no_units_layer_1_1,159.0
reconciliation_loss_lambda,0.020103265988878335
no_layers,1
no_units_layer,[159]
