,0
batch_size,27.0
dropout_rate,0.18739451804985183
epochs,15.0
layers,4
learning_rate,0.0011823828918762463
max_norm_value,1.4104472357726854
no_units_layer_5_1,176.0
no_units_layer_5_2,208.0
no_units_layer_5_3,2.0
no_units_layer_5_4,184.0
no_units_layer_5_5,154.0
reconciliation_loss_lambda,0.0892737601765623
no_layers,5
no_units_layer,"[176, 208, 2, 184, 154]"
