,0
batch_size,7.0
dropout_rate,0.2916738760933678
epochs,195.0
layers,3
learning_rate,0.02224827162829727
max_norm_value,4.873906107761062
no_units_layer_4_1,157.0
no_units_layer_4_2,156.0
no_units_layer_4_3,33.0
no_units_layer_4_4,70.0
reconciliation_loss_lambda,0.8728772225732387
no_layers,4
no_units_layer,"[157, 156, 33, 70]"
