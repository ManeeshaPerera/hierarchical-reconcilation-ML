,0
batch_size,10.0
dropout_rate,0.023481841783481783
epochs,16.0
layers,4
learning_rate,0.0019313790093473276
max_norm_value,9.958885232163157
no_units_layer_5_1,148.0
no_units_layer_5_2,250.0
no_units_layer_5_3,126.0
no_units_layer_5_4,155.0
no_units_layer_5_5,229.0
reconciliation_loss_lambda,4.7609816226337776
no_layers,5
no_units_layer,"[148, 250, 126, 155, 229]"
