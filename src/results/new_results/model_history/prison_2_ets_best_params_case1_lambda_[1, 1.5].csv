,0
batch_size,19.0
dropout_rate,0.04343737235393459
epochs,124.0
layers,4
learning_rate,0.0028662567633845545
max_norm_value,2.332827821263755
no_units_layer_5_1,14.0
no_units_layer_5_2,201.0
no_units_layer_5_3,186.0
no_units_layer_5_4,178.0
no_units_layer_5_5,59.0
reconciliation_loss_lambda,1.0828626799720946
no_layers,5
no_units_layer,"[14, 201, 186, 178, 59]"
