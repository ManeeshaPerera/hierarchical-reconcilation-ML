,0
batch_size,30.0
dropout_rate,0.46178401150084464
epochs,157.0
layers,4
learning_rate,0.00043325341927002504
max_norm_value,6.479232382748446
no_units_layer_5_1,197.0
no_units_layer_5_2,203.0
no_units_layer_5_3,184.0
no_units_layer_5_4,56.0
no_units_layer_5_5,47.0
reconciliation_loss_lambda,4.689163699527567
no_layers,5
no_units_layer,"[197, 203, 184, 56, 47]"
