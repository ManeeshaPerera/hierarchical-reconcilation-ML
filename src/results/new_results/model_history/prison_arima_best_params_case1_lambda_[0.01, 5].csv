,0
batch_size,19.0
dropout_rate,0.3631690210898178
epochs,133.0
layers,1
learning_rate,0.01612037527922118
max_norm_value,5.589621582349303
no_units_layer_2_1,65.0
no_units_layer_2_2,133.0
reconciliation_loss_lambda,2.551492818137998
no_layers,2
no_units_layer,"[65, 133]"
