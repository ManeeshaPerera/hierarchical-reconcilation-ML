,0
batch_size,76.0
dropout_rate,0.2657138943277394
epochs,70.0
layers,1
learning_rate,0.0003807473386143456
max_norm_value,7.751914555447628
no_units_layer_2_1,96.0
no_units_layer_2_2,231.0
reconciliation_loss_lambda,0.8618974888080562
no_layers,2
no_units_layer,"[96, 231]"
