,0
batch_size,105.0
dropout_rate,0.14353759103881508
epochs,23.0
layers,4
learning_rate,0.04252880862408035
max_norm_value,7.888871093213616
no_units_layer_5_1,249.0
no_units_layer_5_2,253.0
no_units_layer_5_3,254.0
no_units_layer_5_4,9.0
no_units_layer_5_5,1.0
reconciliation_loss_lambda,1.1991312504699922
no_layers,5
no_units_layer,"[249, 253, 254, 9, 1]"
