,0
batch_size,110.0
dropout_rate,0.43769284696866634
epochs,70.0
layers,1
learning_rate,0.0006177629517400097
max_norm_value,7.1311803390206
no_units_layer_2_1,76.0
no_units_layer_2_2,181.0
reconciliation_loss_lambda,2.0605881346619657
no_layers,2
no_units_layer,"[76, 181]"
