,0
batch_size,9.0
dropout_rate,0.4344986328641191
epochs,181.0
layers,4
learning_rate,0.03865090964482756
max_norm_value,7.8490517005586335
no_units_layer_5_1,6.0
no_units_layer_5_2,189.0
no_units_layer_5_3,51.0
no_units_layer_5_4,3.0
no_units_layer_5_5,167.0
reconciliation_loss_lambda,1.2437589803733744
no_layers,5
no_units_layer,"[6, 189, 51, 3, 167]"
