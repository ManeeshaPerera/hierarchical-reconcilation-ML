,0
batch_size,21.0
dropout_rate,0.43601978927544505
epochs,55.0
layers,3
learning_rate,0.013550913540857839
max_norm_value,7.480896237341582
no_units_layer_4_1,256.0
no_units_layer_4_2,96.0
no_units_layer_4_3,96.0
no_units_layer_4_4,253.0
reconciliation_loss_lambda,0.21032924760184374
no_layers,4
no_units_layer,"[256, 96, 96, 253]"
