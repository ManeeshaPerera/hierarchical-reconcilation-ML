,0
batch_size,84.0
dropout_rate,0.46674450802571193
epochs,103.0
layers,3
learning_rate,0.0537280273852561
max_norm_value,2.3456190093669385
no_units_layer_4_1,86.0
no_units_layer_4_2,162.0
no_units_layer_4_3,256.0
no_units_layer_4_4,165.0
reconciliation_loss_lambda,2.746366680071577
no_layers,4
no_units_layer,"[86, 162, 256, 165]"
