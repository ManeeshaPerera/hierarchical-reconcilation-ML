,0
batch_size,6.0
dropout_rate,0.433815444050983
epochs,77.0
layers,3
learning_rate,0.0463986533295446
max_norm_value,5.275467121992568
no_units_layer_4_1,56.0
no_units_layer_4_2,250.0
no_units_layer_4_3,232.0
no_units_layer_4_4,16.0
reconciliation_loss_lambda,4.991921718375189
no_layers,4
no_units_layer,"[56, 250, 232, 16]"
