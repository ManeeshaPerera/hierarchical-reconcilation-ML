,0
batch_size,15.0
dropout_rate,0.2501890723125187
epochs,51.0
layers,3
learning_rate,0.06644809924018986
max_norm_value,2.299490577985289
no_units_layer_4_1,1.0
no_units_layer_4_2,221.0
no_units_layer_4_3,84.0
no_units_layer_4_4,127.0
reconciliation_loss_lambda,0.07281586795796295
no_layers,4
no_units_layer,"[1, 221, 84, 127]"
