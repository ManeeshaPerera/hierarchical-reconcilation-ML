,0
batch_size,28.0
dropout_rate,0.002692113185448902
epochs,11.0
layers,2
learning_rate,0.0003006536618841305
max_norm_value,9.283895000627082
no_units_layer_3_1,12.0
no_units_layer_3_2,8.0
no_units_layer_3_3,251.0
reconciliation_loss_lambda,0.04499840458398588
no_layers,3
no_units_layer,"[12, 8, 251]"
