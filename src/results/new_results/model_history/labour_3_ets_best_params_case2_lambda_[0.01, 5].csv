,0
batch_size,41.0
dropout_rate,0.176620163683052
epochs,88.0
layers,1
learning_rate,0.00014643123074431323
max_norm_value,0.6229759716626434
no_units_layer_2_1,123.0
no_units_layer_2_2,196.0
reconciliation_loss_lambda,1.9753301663413845
no_layers,2
no_units_layer,"[123, 196]"
