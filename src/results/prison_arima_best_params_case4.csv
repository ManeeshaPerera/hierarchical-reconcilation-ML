,0
batch_size,18.0
dropout_rate,0.2725875163079655
epochs,189.0
layers,1
learning_rate,0.06835559485460652
max_norm_value,1.2389331718058543
no_units_layer_2_1,159.0
no_units_layer_2_2,17.0
reconciliation_loss_lambda,0.2801087072756977
no_layers,2
no_units_layer,"[159, 17]"
