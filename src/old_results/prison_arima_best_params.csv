batch_size,dropout_rate,epochs,layers,learning_rate,max_norm_value,no_units_layer_1_1,reconciliation_loss_lambda,no_layers,no_units_layer
32.0,0.47278859910201154,57.0,0,0.051703141799186274,2.2837143021272928,5.0,0.6056146835375975,1,5
